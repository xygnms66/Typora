# TensorRT

## 基础概念

TensorRT是一个高性能的深度学习推理（Inference）优化器，可以为深度学习应用提供低延迟、高吞吐率的部署推理。TensorRT可用于对超大规模数据中心、嵌入式平台或自动驾驶平台进行推理加速。TensorRT现已能支持TensorFlow、Caffe、Mxnet、Pytorch等几乎所有的深度学习框架，将TensorRT和NVIDIA的GPU结合起来，能在几乎所有的框架中进行快速和高效的部署推理。

![Training-vs-Inference-1](E:\Document\Typora\img\Training-vs-Inference-1.jpg)

![Training-vs-Inference-2](E:\Document\Typora\img\Training-vs-Inference-2.jpg)

由以上两张图可以很清楚的看出，训练（training）和 推理（inference）的区别：

- 训练（training）包含了前向传播和后向传播两个阶段，针对的是训练集。训练时通过误差反向传播来不断修改网络权值（weights）。
- 推理（inference）只包含前向传播一个阶段，针对的是除了训练集之外的新数据。可以是测试集，但不完全是，更多的是整个数据集之外的数据。其实就是针对新数D:\dev\code\preprocess\src\main.cpp D:\dev\code\preprocess\src\preprocess\ZJReidDetector.h D:\dev\code\preprocess\depends\include\ZJLabCV_Detect_win.h D:\dev\code\preprocess\.vscode\c_cpp_properties.json D:\dev\code\preprocess\src\ZJReidBuffer.h据进行预测，预测时，速度是一个很重要的因素。

而tensorRT 则是对训练好的模型进行优化。 tensorRT就只是 推理优化器。当你的网络训练完之后，可以将训练模型文件直接丢进tensorRT中，而不再需要依赖深度学习框架（Caffe，TensorFlow等），如下：



## 使用流程

![TensorRT](E:\Document\Typora\img\TensorRT.png)

~~~
    IRuntime* runtime = createInferRuntime(gLogger);
    ZJLABCVASSERT(runtime != nullptr,ZJLAB_CV_ERROR);

    ICudaEngine* engine = runtime->deserializeCudaEngine(trtModelStream, size);
    ZJLABCVASSERT(engine != nullptr,ZJLAB_CV_ERROR);

    IExecutionContext* context = engine->createExecutionContext();
    ZJLABCVASSERT(context != nullptr,ZJLAB_CV_ERROR);
~~~

+ **ILogger**，全局变量，在大多数TensorRT的API中都会作为参数使用；

+ **IBuilder**，通过 createInferBuilder(gLogger) 创建；
+ **iNetworkDefinition**，在IBuilder对象中调用createNetwork()获取；
+ **IRuntime**，通过 createInferRuntime(gLogger) 创建。
+ **ICudaEngine**，TensorRT的引擎，通过对模型序列化buildCudaEngine(*network)、读取已经序列化的文件deserializeCudaEngine()两种方式产生，后者在前者基础上通过serialize()获得，因此使用更方便；





# 环境安装

[Pytorch入门+实战系列一：Windows下的Pytorch环境手把手搭建_Miracle8070-CSDN博客_pycharm pytorch入门](https://blog.csdn.net/wuzhongqiang/article/details/104503860)

GPU型号`NVIDIA GeForce RTX 3070`

Nvidia版本安装    当前`11.3`

cuDNN安装 [cuDNN Archive | NVIDIA Developer](https://developer.nvidia.com/rdp/cudnn-archive)



pytorch安装教程

[win10 安装 pytorch - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/174738684)

[anaconda3安装pytorch并在pycharm创建torch环境_Nirvana_xian的博客-CSDN博客](https://blog.csdn.net/Nirvana_xian/article/details/115680532)

[Pytorch入门+实战系列一：Windows下的Pytorch环境手把手搭建_Miracle8070-CSDN博客_pycharm pytorch入门](https://blog.csdn.net/wuzhongqiang/article/details/104503860)

pytorch的路径

https://download.pytorch.org/whl/torch_stable.html

## pytorch安装

![image-20211101154121587](E:\Document\Typora\img\image-20211101154121587.png)

创建一个torch环境：输入：conda create -n 环境名称 [python](https://so.csdn.net/so/search?from=pc_blog_highlight&q=python)=3.8

```conda create -n torch python=3.6
conda create -n torch python=3.8
```

修改镜像源

```
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
conda config --set show_channel_urls yes
```

根据Pytorch官网 [Start Locally | PyTorch](https://pytorch.org/get-started/locally/)的命令

![image-20211101154249687](E:\Document\Typora\img\image-20211101154249687.png)

Pytorch大神的修炼之路：

![image-20211101154355454](E:\Document\Typora\img\image-20211101154355454.png)

安装pytorch时候要注意

把命令`conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch`改为

`conda install pytorch torchvision torchaudio cudatoolkit=11.3 -n pytorch`



# Anconda环境安装Torch

## Anconda环境基础命令

+ 创建torch环境 输入：conda create -n 环境名称 python=3.6

~~~
conda create -n torch python=3.6
~~~

+ 查看已有环境

~~~
conda info -e
~~~

+ 查看安装了哪些包

~~~
conda list
~~~

+ 检查更新当前conda

~~~
conda update conda
~~~

+ 激活所建环境：输入：activate 环境名称

~~~
activate torch
~~~

+ 退出当前环境

~~~
conda deactivate
~~~

+ 删除环境输入

~~~
conda remove -n your_env_name(虚拟环境名称) --all）
~~~

+ 退出python

~~~
quit()
~~~

+ 查看已有的channel

~~~
conda config --show channels
~~~

+ 安装命令  [Start Locally | PyTorch](https://pytorch.org/get-started/locally/)

+ 修改目录

~~~
vim ~/.condarc
~~~

+ 测试安装效果

![image-20210902093101560](E:\Document\Typora\img\image-20210902093101560.png)

+ 恢复默认源

~~~
#conda config --remove-key channels

conda config --add channels https://repo.anaconda.com/pkgs/main
conda config --add channels https://repo.anaconda.com/pkgs/r
conda config --add channels https://repo.anaconda.com/pkgs/msys2
conda config --set show_channel_urls yes
~~~

+ 删除单个源

~~~
conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
~~~





## 安装过程中的报错

[Pytorch安装--报错-CondaHTTPError: HTTP 000 CONNECTION FAILED for url_songchunxiao1991的博客-CSDN博客](https://blog.csdn.net/songchunxiao1991/article/details/95192063)

[CondaHTTPError: HTTP 000 CONNECTION FAILED for url ＜https://mirrors.tuna.tsinghua.edu.cn/anaconda/_titake的博客-CSDN博客](https://blog.csdn.net/qq_22498427/article/details/107792922)



### NVIDIA显卡驱动与CUDA Toolkit版本对照表

![image-20210902103021207](E:\Document\Typora\img\image-20210902103021207.png)

+ torch的cuda无法使用的原因

![image-20210902102058755](E:\Document\Typora\img\image-20210902102058755.png)

CUDA版本：11.3

![image-20210902102145780](E:\Document\Typora\img\image-20210902102145780.png)

这里显示的NVCUDA.DLL不是安装的CUDA版本是你目前显卡驱动所能支持的最高版本。

+ 运行时API :  10.2

![image-20210902102452911](E:\Document\Typora\img\image-20210902102452911.png)

+ driver API : 11.3

CUDA Driver Version是跟nvidia的GPU驱动(nvidia-driver)绑定在一起的：

![image-20210902102528915](E:\Document\Typora\img\image-20210902102528915.png)

。。。最后我也不知道怎么就搞好了

![image-20210902110939975](E:\Document\Typora\img\image-20210902110939975.png)



本地可用环境`pytorch`

![image-20211101172255702](E:\Document\Typora\img\image-20211101172255702.png)

pycharm创建项目

[anaconda3安装pytorch并在pycharm创建torch环境_Nirvana_xian的博客-CSDN博客](https://blog.csdn.net/Nirvana_xian/article/details/115680532)

## 其他安装

**安装opencv**

~~~
pip install opencv-python
~~~

安装matplotlib

~~~
conda install matplotlib
~~~

安装tensorflow，`2.4.0`为版本号

~~~
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple tensorflow-gpu==2.4.0
~~~

安装pyQt5

~~~
pip install PyQt5-tools -i https://pypi.douban.com/simple
~~~

安装`colorama`

~~~
pip install colorama
~~~

安装opencv

~~~
pip install opencv-python
~~~

删除某个版本的numpy

~~~
pip install numpy==1.18.2
~~~

安装tpdm

~~~
pip install tqdm
~~~

安装ffmpeg

~~~
pip install ffmpeg-python
~~~

安装PIL，避免报错

~~~
pip install pillow
~~~



## 最终conda安装配置

`deepfake`配置的环境用于运行`deepfacelab`





# 三维人脸重建

[3D人脸重建--学习笔记_Mingx9527-CSDN博客_人脸重建](https://blog.csdn.net/u011681952/article/details/82623328)

**通用人脸模型（CANDIDE-3**）和**三维变形模型（3DMM）**及其变种模型

+ 采用三维扫描仪获取数据

+ 采用计算机图形技术创建人脸

+ 利用一些商业的建模软件生成人脸通用模型

**CANDIDE-3模型**是目前被学术界广泛使用的一种通用模型，其符合MPEG-4标准中对人脸的定义。

CANDIDE-3模型总共有**113个顶点**，**168个面**组成，可以通过对这些点和面的操作调节形成特定的人脸。

![image-20211111161656317](E:\Document\Typora\img\image-20211111161656317.png)

通用模型重建法的本质是对通用模型进行修改使得其特征与所需要恢复的输入图像相配，一般包括整体性调整和局部性调整两个方面。整体性调整主要是针对模型的轮廓，通过一定的方法如特征点对应使得通用模型的整体布局（如眼耳鼻眉）和输入图片的五官布局尽量一致；局部性调整指的是针对局部细节尤其是人脸五官的微调，让局部细节更为精确。在进行完这两项调整之后，再辅助以基于顶点的插值运算就可以重建人脸。通用模型法的优点是计算量较小，但其显著缺陷就是因顶点数目过少导致对人脸轮廓的模拟和面部细节刻画不够细腻，故只能适用于精度要求不高的场合。





## 论文和方法

[3D人脸重建--学习笔记_Mingx9527-CSDN博客_人脸重建](https://blog.csdn.net/u011681952/article/details/82623328)

### LSFM 

大规模人脸模型（LSTM）



### Nonlinear-3DMM

DNNs来学习Shape和Texture，不需要3D扫描，能够更好地重建人脸。



### VRNet

自己的3D人脸表示方法，即用一个**192\*192\*200的Volumetric**来表示

![image-20211116142550404](E:\Document\Typora\img\image-20211116142550404.png)

### PRNet



[微软三维人脸重建论文总结——《Accurate 3D Face Reconstruction with Weakly-Supervised Learning》_哪咔吗的博客-CSDN博客](https://blog.csdn.net/weixin_37340613/article/details/94599646)

对应论文



### 3DMM入门

[使用3DMM进行人脸重建中的配准方法_likewind1993的博客-CSDN博客_3dmm](https://blog.csdn.net/likewind1993/article/details/81455882)

face3D开源代码   https://github.com/YadiraF/face3d

对应论文  https://blog.csdn.net/likewind1993/article/details/79177566



BFM的使用

[BFM模型介绍及可视化实现（C++）_Addisoni-CSDN博客](https://blog.csdn.net/ling_76539446/article/details/102886398)

BFM分为2009和2017两个版本

~~~
2009与2017版本区别
2009年版本数据集：

提供数据格式：mat（01_MorphableModel.mat）和h5（model2009-publicmm1-bfm.h5）；
提供一系列Matlab脚本，有生成随机脸等功能；
提供多种特征点（PublicMM1/11_feature_points）；
提供segment的mask（PublicMM1/09_mask）；
提供对称点的对应关系（PublicMM1/13_symmetry_indices）；
提供属性（PublicMM1/04_attributes.mat）
不提供表情；
2017年版本数据集：

提供数据格式：h5（原版（model2017-1_bfm_nomouth.h5）和裁剪过的版本（model2017-1_face12_nomouth.h5））；
不提供Matlab脚本（本身也无mat格式数据）；
提供单种特征点（metadata/landmarks/text）；
不提供segment、对称点的对应关系和属性；
提供表情（expression）；
~~~

HDFView可以可视化h5文件

https://www.hdfgroup.org/downloads/hdfview/

账号：731198338@qq.com

密码：xyghf555

C++中使用HDF5读写需要官方库

https://www.hdfgroup.org/downloads/hdf5/?https%3A%2F%2Fwww.hdfgroup.org%2Fdownloads%2Fhdf5%2F

基于HDF5的开发

~~~
官网右上角注册后下载，随后选择对应版本下载。
[注] 在Windows的Visual Studio使用shared库需要编译过程定义H5_BUILT_AS_DYNAMIC_LIB。（若出现LINK2001错误可以添加这个来解决）
[注] static库命名前面以lib开头，例如hdf5.lib是shared库，libhdf5.lib是static库。
在VS的包含目录和库目录中添加对应的inlcude和lib目录。
在链接器的输入中增加szip.lib;zlib.lib;hdf5.lib;hdf5_cpp.lib;，并将对应的.dll文件放置到Windows/System32或Windows/SysWOW64。
~~~

基于HDF5的开发

[Great-Keith/bfm-visual-tool: A Visual Tools of Basel Face Model using Qt5(+built-in OpenGL) and C++ (github.com)](https://github.com/Great-Keith/bfm-visual-tool)





# 人脸识别

[人脸识别之insightface - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/43293887)



## face3d

### 1_pipeline

.mat二进制文件包括：vertices【顶点】, triangles【角度】, color(optinal)【颜色】, texture(optional)【纹理】

shape都为【53215，3】，53215表示该三维图的

数据以字典形式存储

各个key的shape:

| vertices   | colors     | triangles   | full_triangles |
| ---------- | ---------- | ----------- | -------------- |
| (53215, 3) | (53215, 3) | (105840, 3) | (105954, 3)    |

vertices为53215的原因？
 通过BFM形状模型和表情模型，可以得到最终的3D点云的图像坐标(共53215个)，每个点有x,y,z 3个坐标，共有53215x3个值，这些点云中的68个点x,y坐标即为常用的68个人脸关键点，约40k个点的x，y坐标即为密集人脸关键点。点云预测的目标就是从单张2D人脸RGB图像中直接预测这约53k的点的3维坐标值。

~~~
# scale. target size=180 for example
s = 180/(np.max(vertices[:,1]) - np.min(vertices[:,1]))
# rotate 30 degree for example
R = mesh.transform.angle2matrix([0, 30, 0]) 
# no translation. center of obj:[0,0]
t = [0, 0, 0]
transformed_vertices = mesh.transform.similarity_transform(vertices, s, R, t)
~~~

angle2matrix函数把角度转为R计算shape为（3，3）的旋转矩阵

~~~
deg2rad（number）
~~~

把角度值转为弧度值，number表示转换的角度，返回值伪对应的弧度。

~~~
Pitch,Yaw,Roll的概念

pitch是围绕X轴旋转，也叫做俯仰角。
yaw是围绕Y轴旋转，也叫偏航角。
roll是围绕Z轴旋转，也叫翻滚角
~~~

原图

![image-20211118165204805](E:\Document\Typora\img\image-20211118165204805.png)

pitch20

![image-20211118165221948](E:\Document\Typora\img\image-20211118165221948.png)

yaw30

![image-20211118165246236](E:\Document\Typora\img\image-20211118165246236.png)

roll30

![image-20211118165258004](E:\Document\Typora\img\image-20211118165258004.png)

s是180/纵轴的范围

![image-20211118162917023](E:\Document\Typora\img\image-20211118162917023.png)

对应代码`transformed_vertices = mesh.transform.similarity_transform(vertices, s, R, t)`

为三维模型到二维平面的投影

![image-20211118163149330](E:\Document\Typora\img\image-20211118163149330.png)

`transformed_vertices`我理解还没有进行投影，所以shape为[53215,3]

R表示旋转矩阵

s表示缩放比例，`180/(np.max(vertices[:,1]) - np.min(vertices[:,1]))`表示顶点范围不超过180



`numpy.squeeze()`表示删除单维度

`np.newaxis`表示增加一个维度

# pytorch

## 代码框架

~~~
torch_base 
├── checkpoints # 存放模型的地方 
├── data        # 定义各种用于训练测试的dataset 
├── eval.py     # 测试代码 
├── loss.py     # 定义各种花里胡哨的loss 
├── metrics.py  # 定义各种约定俗成的评估指标 
├── model       # 定义各种实验中的模型 
├── options.py  # 定义各种实验参数，以命令行形式传入 
├── README.md   # 介绍一下自己的repo 
├── scripts     # 各种训练，测试脚本 
├── train.py    # 训练代码 
└── utils       # 各种工具代码
~~~

## 给定url加载预训练模型

~~~
torch.utils.model_zoo.load_url(url, model_dir=None)
~~~

在给定URL上加载Torch序列化对象。
通俗点说，就是通过提供的`.pth`文件的url地址来下载指定的`.pth`文件【在pytorch中.pth文件就是模型的参数文件】

### problem

上图中下载缓慢时，如何在已有中加载模型`state_dict = modelzoo.load_url(resnet18_url)`改为`state_dict = torch.load('resnet18-5c106cde.pth')`前者为下载地址，后者为文件绝对位置。







# pyqt

[Anaconda环境下安装及配置PyQt5_北国觅梦-CSDN博客_anaconda pyqt5](https://blog.csdn.net/ChaoFeiLi/article/details/88418248)

## 安装

豆瓣源速度最快

1. 安装pyqt5

~~~
pip install PyQt5 -i https://pypi.douban.com/simple
~~~

2. 安装pyqt5工具包

~~~
pip install PyQt5-tools -i https://pypi.douban.com/simple
~~~

## 配置

+ 编译器配置

![img](https://img-blog.csdn.net/20180823142847856?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R6NDU0Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

+ 工具配置

![image-20211130160549946](E:\Document\Typora\img\image-20211130160549946.png)





## 代码入门

+ 主函数

~~~
from PyQt5 import QtWidgets
import sys

if __name__ == '__main__':
    app = QtWidgets.QApplication(sys.argv)  # 初始化界面
    MainWindow = QtWidgets.QWidget()  # 生成一个主窗口，QtWidgets.QWidget()是QtWidgets的自动窗口，可以替换为继承QWidget的主窗口函数
    MainWindow.show()  # 显示主窗口
    sys.exit(app.exec_())  # 在主线程中退出
~~~

在脚本执行的开始，创建了一个 `QtWidgets.QApplication(sys.argv)` 对象，这个对象负责管理图形用户界面应用程序的 **控制流** 和 **主要设置**，并包含主线程的 **事件循环**。事件循环类似于 Windows 程序设计中的 **消息队列**，负责处理信号和槽之间的关系调用，也就是说没有事件循环，信号和槽连接之后也是没有效果的。`app.exec()` 就是开启了主线程中的事件循环。

+ 带有UI

~~~
from PyQt5.QtWidgets import QApplication, QMainWindow
import sys
import uiDemo1  # .ui文件转为.py文件

if __name__ == '__main__':
    app = QApplication(sys.argv)  # 创建应用程序对象
    MainWindow = QMainWindow()  # 创建主窗口
    ui = uiDemo1.Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()  # 显示主窗口
    sys.exit(app.exec_())  # 在主线程中退出
~~~

### pyqt实现定位相机拍摄位置

实例代码

~~~
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from PyQt5.QtWebEngineWidgets import *
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5 import QtWidgets, QtCore, QtGui
import piexif
import sys

class MainWindow(QWidget):  # 继承 QWidget
    def __init__(self):
        super(MainWindow, self).__init__()
        self.lat = ''  # 纬度
        self.lng = ''  # 经度
        self.fileName = ''  # 图片路径
        self.setWindowTitle('Image positioning')  # 设置窗口标题
        self.verticalLayout_2 = QtWidgets.QVBoxLayout()  # 创建垂直布局
        self.verticalLayout = QtWidgets.QVBoxLayout()
        self.horizontalLayout = QtWidgets.QHBoxLayout()  # 创建水平布局

        # 创建 QTextEdit
        self.textEdit = QtWidgets.QTextEdit()
        # 设置布局尺寸
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.textEdit.sizePolicy().hasHeightForWidth())
        self.textEdit.setSizePolicy(sizePolicy)
        self.textEdit.setMaximumSize(QtCore.QSize(16777215, 30))
        self.horizontalLayout.addWidget(self.textEdit)  # 将 QTextEdit 添加到水平布局中

        # 创建 selectButton
        self.selectButton = QtWidgets.QPushButton('Select')
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.selectButton.sizePolicy().hasHeightForWidth())
        self.selectButton.setSizePolicy(sizePolicy)
        self.horizontalLayout.addWidget(self.selectButton)

        # 创建 positionButton
        self.positionButton = QtWidgets.QPushButton('Position')
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.positionButton.sizePolicy().hasHeightForWidth())
        self.positionButton.setSizePolicy(sizePolicy)
        self.horizontalLayout.addWidget(self.positionButton)
        spacerItem = QtWidgets.QSpacerItem(
            40, 20, QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Minimum)
        self.horizontalLayout.addItem(spacerItem)
        self.verticalLayout.addLayout(self.horizontalLayout)

        # 创建 QWebView
        self.webView = QWebEngineView()
        self.webView.load(QUrl('http://map.baidu.com/'))
        self.verticalLayout.addWidget(self.webView)
        self.verticalLayout_2.addLayout(self.verticalLayout)
        self.setLayout(self.verticalLayout_2)

        self.positionButton.clicked.connect(
            self.reload)  # 连接 clicked 信号到 self.reload() 槽
        # 连接 clicked 信号到 self.getPosition() 槽
        self.selectButton.clicked.connect(self.getPosition)

    def d2l(self, gpsData):  # GPS 经纬度元组转经纬度
        d = gpsData[0][0] / gpsData[0][1]  # 度
        m = gpsData[1][0] / gpsData[1][1]  # 分
        s = gpsData[2][0] / gpsData[2][1]  # 秒
        return str(d + (m + s / 60) / 60)

    def getPosition(self):  # 获取相片中的经纬度并通过 QWebView 调用百度 URI API 实现定位功能
        fileDialog = QFileDialog()  # 创建文件对话框对象
        self.fileName = fileDialog.getOpenFileName()[0]  # 打开文件对话框并获取选择的相片路径
        self.textEdit.setText(self.fileName)  # 将相片路径名显示到 QTextEdit 上
        exifData = piexif.load(self.fileName)  # 加载图片并返回 Exif 数据字典
        if exifData['GPS']:  # 判断是否包含 GPS 数据

            for k, v in exifData['GPS'].items():
                print('-->>', k, v)
            try:
                self.lat = self.d2l(exifData['GPS'][2])  # 获取 GPS 信息中的纬度（度分秒）
                self.lng = self.d2l(exifData['GPS'][4])  # 获取 GPS 信息中的经度（度分秒）
                print('lat:', self.lat)
                print('lng:', self.lng)
            except:
                msg = QMessageBox.information(
                    self, 'Error', 'To locate failure!')  # 消息提示框
        else:
            msg = QMessageBox.information(
                self, 'warning', "This picture doesn't contain the GPS information!")

    # QWebView 加载 URI
    def reload(self):
        self.webView.load(QUrl(
            'http://api.map.baidu.com/geocoder?location=%s,%s&coord_type=gcj02&output=html&src=personal|img_pos' % (self.lat, self.lng)))

if __name__ == '__main__':
    app = QtWidgets.QApplication(sys.argv)
    window = MainWindow()
    window.show()
    app.exec()
~~~

+ QtWidgets.QSizePolicy   [Qt 之 QSizePolicy_青春不老，奋斗不止！-CSDN博客](https://blog.csdn.net/liang19890820/article/details/51986284)

~~~
sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Fixed)
# QSizePolicy类是一个描述布局水平和垂直方向调整策略的属性
sizePolicy.setHorizontalStretch(0)
# 设置水平大小策略的缩放因子，取值范围[0,255]。
sizePolicy.setVerticalStretch(0)
# 设置垂直大小策略的缩放因子，取值范围[0,255]。
sizePolicy.setHeightForWidth(
            self.textEdit.sizePolicy().hasHeightForWidth())
# 设置标志判断窗口部件的首选高度是否依赖于它的宽度。
self.textEdit.setSizePolicy(sizePolicy)
~~~



## QTDesigner

进一步地，在 QtDesigner 创建主窗口有三种类型：QMainWindow、QDialog 和 QWidget。

- QMainWindow：包括菜单栏、工具栏、状态栏和标题栏，常用于应用程序的窗口。
- QDialog：没有菜单栏、工具栏、标题栏，常用于对话框的窗口。QtDesigner 中进一步提供了：没有默认按钮的对话框、底部按钮的对话框和右侧按钮的对话框可供选择。
- QWidget：不确定窗口的类型。

### **编辑窗口的属性**

+ 对象名称（objectName）

![image-20211130170925348](E:\Document\Typora\img\image-20211130170925348.png)

+ 窗口标题（windowsTitle）

![image-20211130171013067](E:\Document\Typora\img\image-20211130171013067.png)

+ Icon

**Normal off到Selected On**
这8个子属性应该是QIcon的两个属性的组合，分别指定部件在这8种状态下使用哪个图标。这两个属性分别是QIcon的如下两个枚举类型成员：

**enum Mode { Normal, Disabled, Active, Selected }，四个值分别表示**：

```
    1）QIcon.Normal：部件为使能状态，但未激活，没有获得焦点。

     2）QIcon.Disabled：部件为禁用状态。

     3）QIcon.Active：部件为激活状态，获得了焦点（如鼠标悬停在上面，或Tab键移动焦点）。

     4）QIcon.Selected：部件被选中。
     当部件的状态切换时，默认的图标绘制函数会自动根据部件的状态重绘图标。
```

**enum State { Off, On }**：
某些部件还有所谓的开关状态（比如一个按钮可以有按下和弹起两个状态），则还可以根据 state 参数来选择不同的图像。

因此上述两个类型的组合对应了8种状态就是Designer图标的8个子属性。
注意：如果theme设置了，则优先使用theme去加载图标，只有找不到的情况下才使用下面每种状态的图标。

# keras初步

~~~
from keras.models import Sequential
from keras.layers import Dense
import numpy as np
# 初始化 model 
model = Sequential()
# 添加全连接层作为第一层，全连接层的节点数为64，激活函数为 relu，以(*, 16) 的数组作为输入
model.add(Dense(units=64, activation='relu', input_shape=(16,)))
# 添加第二个全连接层，节点数为1，激活函数为 sigmoid，在第一层之后就不需要指定输入尺寸了，Keras 会自动计算
model.add(Dense(units=1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', # 定义损失函数为二元交叉熵函数
              optimizer='sgd', # 梯度更新算法为随机梯度下降算法
              metrics=['accuracy']) # 模型的评估标准为精度
model.summary()
# fit 方法接收的第一个数据是训练的输入数据，第二个数据为训练的期望输出数据
model.fit(np.random.rand(32,16),np.ones(32),epochs=30, batch_size=32)
# 训练完成后保存模型参数
model.save('model.h5')
model.predict(np.random.rand(3,16))
~~~

Keras提供的模型，其中分为两类：

- Sequential 顺序模型
- Model 类模型

Dense layer 就是常提到和用到的全连接层 。Dense 实现的操作为：output = activation(dot(input, kernel) + bias) 其中 activation 是按逐个元素计算的激活函数，kernel 是由网络层创建的权值矩阵，以及 bias 是其创建的偏置向量 (只在 use_bias=True 时才有用)。

~~~
keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)

units: 正整数，输出空间维度。
activation: 激活函数 (详见 activations)。 若不指定，则不使用激活函数 (即，「线性」激活: a(x) = x)。
use_bias: 布尔值，该层是否使用偏置向量。
kernel_initializer: kernel 权值矩阵的初始化器 (详见 initializers)。
bias_initializer: 偏置向量的初始化器 (see initializers).
kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数 (详见 regularizer)。
bias_regularizer: 运用到偏置向的的正则化函数 (详见 regularizer)。
activity_regularizer: 运用到层的输出的正则化函数 (它的 "activation")。 (详见 regularizer)。
kernel_constraint: 运用到 kernel 权值矩阵的约束函数 (详见 constraints)。
bias_constraint: 运用到偏置向量的约束函数 (详见 constraints)。
~~~

## 函数式API

函数式 API 用于构建更加复杂的网络结构，它允许构建任意的神经网络图，如多个输入或多个输出，这是 Sequential 顺序模型无法做到的。

- 函数式 API 中网络层的实例是可调用的，它以张量为参数，并且返回一个张量
- 输入和输出均为张量，它们都可以用来定义一个模型

```python
from keras.layers import Input, Dense, concatenate
from keras.models import Model

# 定义第一个输入层，Input 返回一个张量
input1 = Input(shape=(8,))
# 同理定义第二个输入层
input2 = Input(shape=(16,))

# 定义全连接层，接收输入层为参数，并返回一个张量
x1 = Dense(64, activation='relu')(input1)
x2 = Dense(64, activation='relu')(input2)

# 连接两个输出
x = concatenate([x1,x2])

# 定义模型输出
output = Dense(1, activation='sigmoid')(x)

# 定义模型，这里创建了一个包含两个输入和一个输出的全连接模型
model = Model(inputs=[input1, input2], outputs=output)

# 与 Sequential 相同，配置学习过程
model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy']) 

# 通过传递数组的方式进行训练
model.fit([np.random.rand(32,8),np.random.rand(32,16)], np.ones(32))
```

### 3. 全连接层 Dense

```python
keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
```

全连接层实现以下操作： `output = activation(dot(input, kernel) + bias)` 其中 `activation` 是按逐个元素计算的激活函数，`kernel` 是由网络层创建的权值矩阵，以及 `bias` 是其创建的偏置向量 (只在 `use_bias` 为 `True` 时才有用)。

#### 参数设置

- units: 正整数，节点数，即输出空间维度。
- activation: 激活函数。 若不指定，则不使用激活函数。
- use_bias: 布尔值，该层是否使用偏置向量。
- kernel_initializer: kernel 权值矩阵的初始化器。
- bias_initializer: 偏置向量的初始化器。
- kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数。
- bias_regularizer: 运用到偏置向的的正则化函数。
- activity_regularizer: 运用到层的输出的正则化函数。
- kernel_constraint: 运用到 kernel 权值矩阵的约束函数。
- bias_constraint: 运用到偏置向量的约束函数。

#### 输出尺寸

`(batch_size, ..., input_dim)` 的 nD 张量。

#### 输出尺寸

`(batch_size, ..., units)` 的 nD 张量。

### 4. 1D 卷积层 Conv1D

```python
keras.layers.Conv1D(filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
```

1D 卷积层的卷积核以单维度上的层输入进行卷积，以生成输出张量。 如果 `use_bias` 为 `True`， 则会创建一个偏置向量并将其添加到输出中。 最后，如果 `activation` 不是 `None`，也会应用于输出。

#### 参数设置

filters: 整数，输出空间的维度，即卷积核的数量。 kernel_size: 整数，或者单个整数表示的元组或列表，指明 1D 卷积窗口的长度。 strides: 一个整数，或者单个整数表示的元组或列表， 指明卷积的步长。 padding: `"valid"`, `"causal"` 或 `"same"` 之一。`"valid"` 表示不填充。`"same"` 表示填充输入以使输出具有与原始输入相同的长度。 `"causal"` 表示因果（膨胀）卷积。 data_format: 字符串, `"channels_last"` (默认，TensorFlow 作为 backend 时使用) 或 `"channels_first"` 之一。 dilation_rate: 一个整数，或者单个整数表示的元组或列表，指定用于膨胀卷积的膨胀率。 activation: 要使用的激活函数，如未指定，则不使用激活函数。 use_bias: 布尔值，该层是否使用偏置向量。 kernel_initializer: kernel 权值矩阵的初始化器。 bias_initializer: 偏置向量的初始化器。 kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数。 bias_regularizer: 运用到偏置向量的正则化函数。 activity_regularizer: 运用到层输出的正则化函数。 kernel_constraint: 运用到 kernel 权值矩阵的约束函数。 bias_constraint: 运用到偏置向量的约束函数。

#### 输入尺寸

`(batch_size, feature_len, input_dim)` 的 3D 张量

#### 输出尺寸

`(batch_size, new_feature_len, filters)` 的 3D 张量

#### 例子

```python
from keras.layers import Conv1D

model = Sequential()
# 模型将输入一个大小为 (batch, steps, input_dim) 的矩阵
# 模型的输出尺度为 (batch, new_steps, filters)
model.add(Conv1D(filters=32, kernel_size=3,input_shape=(10,12)))

model.compile('rmsprop', 'mse')
# 初始化一个 (32, 10, 12) 的矩阵 
input_array = np.random.randn(32, 10, 12)
output_array = model.predict(input_array)
input_array.shape, output_array.shape
```

### 5. 嵌入层 Embedding

```python
keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)
```

Embedding 层用于将正整数（索引值）转换为固定尺寸的稠密向量，常用于 NLP 模型的第一层，输入数据是用词袋模型等方法提取的正整数值。

#### 参数设置

- input_dim: int > 0。词汇表大小， 即最大整数 index + 1。
- output_dim: int >= 0。词向量的维度。
- embeddings_initializer: embeddings 矩阵的初始化方法。
- embeddings_regularizer: embeddings matrix 的正则化方法。
- embeddings_constraint: embeddings matrix 的约束函数。
- mask_zero: 是否把 0 看作为一个应该被遮蔽的特殊的 "padding" 值。
- input_length: 输入序列的长度。如果需要连接 Flatten 和 Dense 层，则这个参数是必须的，不然 dense 层的输出尺寸就无法计算。

#### 输入尺寸

`(batch_size, sequence_length)` 的 2D 张量

#### 输出尺寸

`(batch_size, sequence_length, output_dim)` 的 3D 张量

#### 例子

```python
from keras.layers import Embedding

model = Sequential()
# 模型将输入一个大小为 (batch, input_length) 的整数矩阵，输入中最大的整数（即词索引）不应该大于 999 （词汇表大小）
# 模型的输出尺度为 (batch, 15, 8)。
model.add(Embedding(1000, 8, input_length=15))


model.compile('rmsprop', 'mse')
# 初始化一个 （4，15）的随机正整数矩阵作为输入
input_array = np.random.randint(1000, size=(4, 15))
output_array = model.predict(input_array)
input_array.shape, output_array.shape
```

### 6. 长短期记忆网络层 LSTM

```python
keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
```

LSTM 是一种特殊的 RNN，能够学习长的依赖关系。

#### 参数设置

- units: 正整数，输出空间的维度。
- activation: 要使用的激活函数。 如果传入 None，则不使用激活函数。
- recurrent_activation: 用于循环时间步的激活函数。 默认：分段线性近似 sigmoid。如果传入 None，则不使用激活函数。
- use_bias: 布尔值，该层是否使用偏置向量。
- kernel_initializer: kernel 权值矩阵的初始化器， 用于输入的线性转换。
- recurrent_initializer: recurrent_kernel 权值矩阵 的初始化器，用于循环层状态的线性转换。
- bias_initializer:偏置向量的初始化器。
- unit_forget_bias: 布尔值。 如果为 True，初始化时，将忘记门的偏置加 1。 将其设置为 True 同时还会强制 bias_initializer="zeros"。
- kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数。
- recurrent_regularizer: 运用到 recurrent_kernel 权值矩阵的正则化函数。
- bias_regularizer: 运用到偏置向量的正则化函数。
- activity_regularizer: 运用到层输出（它的激活值）的正则化函数。
- kernel_constraint: 运用到 kernel 权值矩阵的约束函数。
- recurrent_constraint: 运用到 recurrent_kernel 权值矩阵的约束函数。
- bias_constraint: 运用到偏置向量的约束函数。
- dropout: 在 0 和 1 之间的浮点数。 单元的丢弃比例，用于输入的线性转换。
- recurrent_dropout: 在 0 和 1 之间的浮点数。 单元的丢弃比例，用于循环层状态的线性转换。
- implementation: 实现模式，1 或 2。 模式 1 将把它的操作结构化为更多的小的点积和加法操作， 而模式 2 将把它们分批到更少，更大的操作中。 这些模式在不同的硬件和不同的应用中具有不同的性能配置文件。
- return_sequences: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。
- return_state: 布尔值。除了输出之外是否返回最后一个状态。
- go_backwards: 布尔值。默认 False，如果为 True，则向后处理输入序列并返回相反的序列。
- stateful: 布尔值。默认 False， 如果为 True，则批次中索引 i 处的每个样品的最后状态 将用作下一批次中索引 i 样品的初始状态。
- unroll: 布尔值。默认 False，如果为 True，则网络将展开，否则将使用符号循环。

#### 输入尺寸

`(batch_size, feature_len, input_dim)` 的 3D 张量

#### 输出尺寸

- 若 return_sequences 为 False，只输出序列最后一个值，为 `(batch_size, units)` 的 2D 张量

- 若 return_sequences 为 True，输出全部序列，为

   

  ```
  (batch_size, new_feature_len,units)
  ```

   

  的 2D 张量

  #### 例子

```python
from keras.layers import LSTM 

model = Sequential()
# 模型将输入一个大小为 (batch, feature_len, input_dim) 的矩阵
# 模型的输出尺度为 (batch, 1000)。
model.add(LSTM(units=1000,return_sequences=True,input_shape=(10,3)))
model.compile('rmsprop', 'mse')
# 初始化一个 （4, 10, 3）的随机矩阵作为输入
input_array = np.random.randn(4, 10, 3)
output_array = model.predict(input_array)
input_array.shape, output_array.shape
```

### 双向封装器 Bidirectional

```
keras.layers.Bidirectional(layer, merge_mode='concat', weights=None)
```

RNN 的双向封装器，对序列进行前向和后向计算。

#### 参数设置

- layer: Recurrent 实例。
- merge_mode: 前向和后向 RNN 的输出的结合模式。 为 {'sum', 'mul', 'concat', 'ave', None} 其中之一。 如果是 None，输出不会被结合，而是作为一个列表被返回。
- weights: 要在 Bidirectional 模型中加载的初始权重

#### 例子

```python
from keras.layers import Bidirectional

model = Sequential()
# 封装 LTSM 层为 Bi-LSTM
model.add(Bidirectional(LSTM(10, return_sequences=True),
                        input_shape=(5, 10)))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
# 输出模型信息
model.summary()
```

## 三、总结

在本实验中，我们学习了 Keras 的基本使用方法，在后续的实验中，我们将用 Keras 进行命名实体识别和关系抽取的任务。

Keras 最初发行的时候，TensorFlow 还没有开源。那时的 Keras 主要使用的是 Theano 后端。2015年底 TensorFlow 开源后，Keras 才开始搭建TensorFlow 后端。如今 TensorFlow 是 Keras 最常用的后端。特别是在 TensorFlow 2.0 发行之后，TensorFlow 2.0 删除了篇冗余API，使用 Keras 和 eager execution 轻松构建模型。因此，本教程中的 Keras 代码均可以用 `tf.keras` 进行无缝转换。

