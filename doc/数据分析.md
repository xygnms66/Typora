# 大豆育种项目

+ vue前端配置：使用contain的8080端口，映射到外部访问
+ 内部flask和vue前后端互联，URL:http://10.101.5.14:9527



# 数据分析

## vscode搭建python运行环境

anconda创建环境

~~~
conda create -n analyze python=3.8
~~~

查看

~~~
conda info -e
~~~

![image-20220310144428654](E:\Document\Typora\img\image-20220310144428654.png)

修改解释器

# python基础

## list

+ append和extend





## 字符串

可以通过几种不同的方式表示字符串。如单引号（`'...'`）或双引号（`"..."`）。下面的例子能帮助你更好的理解字符串。

```python
>>> s = "I am Chinese"
>>> s
'I am Chinese'
>>> s = 'I am Chinese'
>>> s = "Here is a line \
... split in two lines"
>>> s
'Here is a line split in two lines'
>>> s = "Here is a line \n split in two lines"
>>> s
'Here is a line \n split in two lines'
>>> print(s)
Here is a line
 split in two lines
```

如果你想要分几行输入字符串，并且希望行尾的换行符自动包含到字符串当中，可以使用三对引号：`"""..."""` 或 `'''...'''` 。

```python
>>> print("""\
... Usage: thingy [OPTIONS]
...      -h                        Display this usage message
...      -H hostname               Hostname to connect to
... """)
Usage: thingy [OPTIONS]
     -h                        Display this usage message
     -H hostname               Hostname to connect to
```

每一个字符串对象都有几个可用的内建方法，我们已经使用过一些了，比如 `s.split()`。

```python
>>> s = "shi yan lou"
>>> s.title()
'Shi Yan Lou'
```

方法 `title()` 返回字符串的标题版本，即单词首字母大写其余字母小写。

```python
>>> z = s.upper()
>>> z
'SHI YAN LOU'
>>> z.lower()
'shi yan lou'
```

方法 `upper()` 返回字符串全部大写的版本，反之 `lower()` 返回字符串的全部小写版本。

```python
>>> s = "I am A pRoGraMMer"
>> s.swapcase()
'i AM a PrOgRAmmER'
```

方法 `swapcase()` 返回字符串大小写交换后的版本 :）

```python
>>> s = "jdwb 2323bjb"
>>> s.isalnum()
False
>>> s = "jdwb2323bjb"
>>> s.isalnum()
True
```

方法 `isalnum()` 检查所有字符是否只有字母和数字，上面的代码中第一行的字符串 `s` 中包含空格字符，所以返回 `False`。

```python
>>> s = "SankarshanSir"
>>> s.isalpha()
True
>>> s = "Sankarshan Sir"
>>> s.isalpha()
False
```

方法 `isalpha()` 检查字符串之中是否只有字母。

```python
>>> s = "1234"
>>> s.isdigit() # 检查字符串是否所有字符为数字
True
>>> s = "ShiYanLou is coming"
>>> s.islower() # 检查字符串是否所有字符为小写
False
>>> s = "Shiyanlou Is Coming"
>>> s.istitle() # To 检查字符串是否为标题样式
True
>>> s = "CHINA"
>>> s.isupper() # 检查字符串是否所有字符为大写
True
```

我们可以使用 `split()` 分割任意字符串，`split()` 允许有一个参数，用来指定字符串以什么字符分隔（默认为 `" "`），它返回一个包含所有分割后的字符串的列表。

```python
>>> s = "We all love Python"
>>> s.split()
['We', 'all', 'love', 'Python']
>>> x = "shiyanlou:is:waiting"
>>> x.split(':')
['shiyanlou', 'is', 'waiting']
```

相反的，方法 `join()` 使用指定字符连接多个字符串，它需要一个包含字符串元素的列表作为输入然后连接列表内的字符串元素。

```python
>>> "-".join("GNU/Linux is great".split())
'GNU/Linux-is-great'
```

在上面的例子中，我们基于空格 `" "` 分割字符串 `"GNU/Linux is great"`，然后用 `"-"` 连接它们。

字符串有几个进行剥离操作的方法。最简单的一个是 `strip(chars)`，用来剥离字符串首尾中指定的字符，它允许有一个字符串参数，这个参数为剥离哪些字符提供依据。不指定参数则默认剥离掉首尾的空格和换行符，代码如下：

```python
>>> s = "  a bc\n "
>>> s.strip()
'a bc'
```

你可以使用 `lstrip(chars)` 或 `rstrip(chars)` 只对字符串左或右剥离。

```python
>>> s = "www.foss.in"
>>> s.lstrip("cwsd.") #删除在字符串左边出现的'c','w','s','d','.'字符
'foss.in'
>>> s.rstrip("cnwdi.") #删除在字符串右边出现的'c','n','w','d','i','.'字符
'www.foss'
```

字符串有一些方法能够帮助你搜索字符串里的文本或子字符串。下面给出示例：

```python
>>> s = "faulty for a reason"
>>> s.find("for")
7
>>> s.find("fora")
-1
>>> s.startswith("fa") # 检查字符串是否以 fa 开头
True
>>> s.endswith("reason") # 检查字符串是否以 reason 结尾
True
```

`find()` 能帮助你找到第一个匹配的子字符串，没有找到则返回 -1。

回文是一种无论从左还是从右读都一样的字符序列。比如 “madam”。在这个例子中，我们检查用户输入的字符串是否是回文，并输出结果。

代码写入文件 `/home/shiyanlou/palindrome.py`：

```python
#!/usr/bin/env python3
s = input("Please enter a string: ")
z = s[::-1]  #把输入的字符串s 进行倒序处理形成新的字符串z
if s == z:
    print("The string is a palindrome")
else:
    print("The string is not a palindrome")
```

运行程序：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid212737labid2042timestamp1471398026951.png)

在讲解单词计数之前我们先了解一个概念：格式化操作符（%）。

我们先看下面的这个例子：

```python
print("my name is %s.I am %d years old" % ('Shixiaolou',4))
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid600404labid2042timestamp1539601037298.png)

在这个例子中，`%s` 为第一个格式符，表示一个字符串；`%d` 为第二个格式符，表示一个整数。格式符为真实值预留位置，并控制显示的格式。常用的有：

- `%s` 字符串（用 str() 函数进行字符串转换）
- `%r` 字符串（用 repr() 函数进行字符串转换）
- `%d` 十进制整数
- `%f` 浮点数
- `%%` 字符 `%`

那么接下来我们对用户输入的一行文本进行单词计数。

代码写入文件 `/home/shiyanlou/countwords.py`：

```python
#!/usr/bin/env python3
s = input("Enter a line: ")
print("The number of words in the line are %d" % (len(s.split(" "))))
```

运行程序：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid212737labid2042timestamp1471398035820.png)

## json

`dump`和`dumps`对`python`对象进行[序列化](https://so.csdn.net/so/search?q=序列化&spm=1001.2101.3001.7020)。将一个`Python`对象进行`JSON`格式的编码。

`load`和`loads`反序列化方法,将`json`格式数据解码为`python`对象。

+ load和loads

~~~
import json

dict = '{"name": "Tom", "age": 23}'   # 将字符串还原为dict
data1 = json.loads(dict)
print(data1, type(data1))

with open("test.json", "r", encoding='utf-8') as f:   # open打开文件，read进行读取
    data2 = json.loads(f.read())    # load的传入参数为字符串类型
    print(data2, type(data2))
    f.seek(0)                       # 将文件游标移动到文件开头位置
    data3 = json.load(f)
    print(data3, type(data3))
~~~

首先在终端中，通过以下命令下载用户学习数据 json 文件 `user_study.json`:

```
cd ~/Code
wget http://labfile.oss.aliyuncs.com/courses/764/user_study.json
```

`user_study.json` 文件部分内容展示如下：

```
{"minutes": 30, "created_at": "2016-05-01 00:00:10", "user_id": 199071, "lab": "\u7528\u6237\u53ca\u6587\u4ef6\u6743\u9650\u7ba1\u7406", "course": "Linux \u57fa\u7840\u5165\u95e8\uff08\u65b0\u7248\uff09"}
```

可以看到，文件中每一项为用户学习记录，代表某用户的某一次学习，其中每一项字段含义如下：

- `user_id` 用户 ID
- `lab` 实验名称
- `course` 课程名称
- `minutes` 学习分钟数
- `created_at` 学习时间

在本挑战中，你需要在 `~/Code/analysis.py` Python 文件中编写一个解析并统计学习数据的函数 `analysis`，`analysis` 函数接受两个参数。第一个参数为学习数据 json 文件名称，其文件内容格式和 `user_study.json` 文件格式一致，第二个参数为 用户 ID。你需要在函数中解析 json 文件中，并从中统计出第二个参数指定的用户 ID 的学习时间和总学习分钟数，也就是说函数将返回两个值，第一个为指定用户的学习时间，第二个为指定用户的总学习分钟数。

~~~
import json

def analysis(file, user_id):
    times = 0
    minutes = 0
    with open(file,'r+', encoding='utf-8') as f:
        data = json.load(f)
        for key in data:
            if key['user_id'] == user_id:
                minutes += key['minutes']
                times += 1
    return times,minutes
~~~

## csv

csv文件的写入`writerow`和`writerows`[python3：csv的读写_katyusha1的博客-CSDN博客_csv python](https://blog.csdn.net/katyusha1/article/details/81606175)

~~~
f = open("01_gene.csv", 'w+')
w_csv = csv.writer(f)
headers = ['id','chrom','pos','REF','ALT']
w_csv.writerow(headers)
isBegin = False
time = 1
with open('F4_01') as f:
    for line in f.readlines():
        curLine=line.strip().split()
        if (False == isBegin):
            if ('#CHROM' == curLine[0]):
                isBegin = True
            continue
        rows = []
        for i in range(5):
            rows.append(curLine[i])
        w_csv.writerow(rows)
        time = time + 1
        if time == 8:
            break
~~~

+ csv写入有空行`open("01_gene.csv", 'w+')`改为`f = open("01_gene.csv", 'w+', newline='')`

~~~
在打开文件的方法里面设置参数：newline=‘’   即可

import csv
 
with open('data.csv','w',newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['id','name','age'])
    writer.writerow(['10001','ZhangSan',18])
    writer.writerow(['10002','LiSi','20'])
~~~

+ csv的reader

![img](https://images2017.cnblogs.com/blog/1318293/201801/1318293-20180129095633500-1731063543.png)

+ 特定行读取

[Python3实现从文件中读取指定行的方法 - 深度学习1 - 博客园 (cnblogs.com)](https://www.cnblogs.com/lindaxin/p/8073769.html)

### 使用pandas处理csv

[Python之Pandas 简介与Pandas 读取csv文件及相关操作01 - 雨后观山色 - 博客园 (cnblogs.com)](https://www.cnblogs.com/luckyplj/p/13193985.html)

+ pandas存储csv

~~~
save = pd.DataFrame(DATA,index=['row1','row2','row3'],columns=['english','number'])
print(save)
save.to_csv('test1.csv',sep=',')
~~~

+ 获取某个单元数值

[从pandas DataFrame获取某个单元格值_浮点型队友的博客-CSDN博客_pandas取某个单元格的值](https://blog.csdn.net/weixin_42159940/article/details/113829094?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_default&utm_relevant_index=1)







## numpy和pandas

+ numpy

![image-20220311162904695](E:\Document\Typora\img\image-20220311162904695.png)

NumPy 的多维数组还有一些方法，可以用于统计数组中一些统计量，假如 `a` 为一个多维数组，则：

- `a.sum` 计算多维数组的所有元素的和；
- `a.max` 最大值计算；
- `a.min` 最小值计算；
- `a.mean` 平均值计算；
- `a.std` 标准差计算；
- `a.var` 方差计算；

以上所有方法，都可以接受一个 `axis` 参数，用于指定具体统计哪根轴上的数据。比如二维数组，可以理解为有 `x, y` 两根轴，分别代表行和列，指定 `axis=0` 时代表分别统计每列上的数据，`axis=1` 时，代表分别统计每一行上的数据。没有指定`axis` 参数时，代表统计所有元素。示例练习如下：

+ pandas数据处理包

在数据分析中，我们更多的针对表格数据进行处理，也就是 NumPy 中的二维数组数据，尽管 NumPy 对于多维数组的支持已经足够强大，但 Pandas 处理这些二维数据时更加得心应手。Pandas 建立在 NumPy 基础之上，但增加了更加高级实用的功能，比如数据自动对齐功能，时间序列的支持，缺失数据的灵活处理等等。在接下来的实验中，我们将学习 Pandas 的基础知识，在学习的过程中一定要实践实例中的代码，只有这样才能真正掌握本节实验的内容。

### Series 和 DataFrame

Series 和 DataFrame 是 Pandas 中的两种核心数据结构，大部分 Pandas 的功能都围绕着两种数据结构进行。

Series 是值的序列，可以理解为一维数组，它只有一个列和索引。索引可以定制，当不指定时默认使用整数索引，而且索引可以被命名：

![image-20220311163320729](E:\Document\Typora\img\image-20220311163320729.png)

![image-20220311163243601](E:\Document\Typora\img\image-20220311163243601.png)

以上代码中先后创建了 `s1` 和 `s2` 两个序列，前一个使用了默认的整数索引，后一个使用了我们指定的字符索引，同时还可以我们可以对索引进行命名。

DataFrame 类似于二维数组，有行和列之分，除了像 Series 一样，多个行有索引而外，每个列上面还可以有标签 `label`, 索引和标签本身都可以被命名：

![image-20220311163435168](E:\Document\Typora\img\image-20220311163435168.png)

### series操作

~~~
 Series.values_count()
~~~

确认数据出现的频率，类型为series







### 选择

类似于 NumPy 数组，当生成了 Series 和 DataFrame 数据时，我们怎么选择其中的部分数据呢？对于 Series 数据来说，主要通过其索引来进行选择：

![image-20220311163603133](E:\Document\Typora\img\image-20220311163603133.png)

可以看到对于指定了索引的 Series 序列来说，我们有两种选择元素的方式，一种是以整数索引（这说明整数索引一直默认存在），第二种方式是通过指定的字符索引进行。其实整数索引和字符索引，分别调用了 `s2.iloc` 和 `s2.loc` 索引，其中 `iloc` 代表整数索引，如下代码：

![image-20220311163653641](E:\Document\Typora\img\image-20220311163653641.png)

对于 DataFrame 数据来说，由于有行列之分，所以可以有多种选择数据的方式，比如通过索引或者标签来选择，先看看对于标签（列）怎么选择：

![image-20220311163738321](E:\Document\Typora\img\image-20220311163738321.png)

可以看到，对于标签（列）选择来说，可以直接通过访问 `df.A` 的属性方式，或者通过 `df['A']` 的方式来选择某一列，如果要选择多列怎么操作呢？前面我们说过，可以通过 `df.columns` 获取到所有的列标签，然后可以根据选择部分标签来选择 `df` 的多列数据：

![image-20220311163800703](E:\Document\Typora\img\image-20220311163800703.png)

当然还有其他方法来选择多列数据，现在先看下如何来选择 `df` 的某行，前面我们提到过可以根据 `loc` 属性来选择某一行，`iloc` 根据整数索引来选择某一行，这些在 DataFrame 中都是可以的：

![image-20220311163812647](E:\Document\Typora\img\image-20220311163812647.png)

![image-20220311163906921](E:\Document\Typora\img\image-20220311163906921.png)

![image-20220311163954672](E:\Document\Typora\img\image-20220311163954672.png)

可以看到非常简单，有了行选择的方式以后，我们有另外一些方法来选择多个列：

![image-20220311164006443](E:\Document\Typora\img\image-20220311164006443.png)

以上代码中 `df.loc` 支持二维的选择，也就是同时选择行和列， `:` 符号代表选择所有的行。由此知道，如果要同时选择具体的某一行和列就非常简单了：

![image-20220311164019001](E:\Document\Typora\img\image-20220311164019001.png)

![image-20220311164029848](E:\Document\Typora\img\image-20220311164029848.png)

### 确实值和数据自动对齐

在 Pandas 中最重要的一个功能是，它可以对不同索引的对象进行算术运算。比如将两个 Series 数据进行相加时，如果存在不同的索引，则结果是两个索引的并集，什么意思呢？通过例子看下：

![image-20220311165412682](E:\Document\Typora\img\image-20220311165412682.png)

以上代码中创建了两个 `s1` 和 `s2` 两个 Series 序列，两者具有相同的索引 `['b', 'c', 'd']`, 所以在进行相加时，相同索引上的值会相加，但不重叠的索引引入 `NaN` 值，也就是缺失值。而缺失值会在运算中传播，所以最终结果也是 `NaN` 值。根据相同的索引进行自动计算，这就是自动对齐功能。同样的规则，在 DataFrame 数据中也生效：

![image-20220311165749737](E:\Document\Typora\img\image-20220311165749737.png)

可以看到，DataFrame 的计算也会进行自动对齐操作，这个时候没有的行或者列会使用 `NaN` 值自动填充，而由于 `NaN` 值会传播，所以相加的结果也是 `NaN`。当然我们在计算时，可以指定使用值来填充 `NaN` 值，然后带入计算过程，如下所示：

我们指定了使用 `0` 填充 `NaN` 值，然后带入计算过程，注意这里填充的不是最终的运算结果。可以看到依然有元素为 `NaN` 值，这是因为这个位置的元素在 `df1` 和 `df2` 中都未定义。

大部分的 Series 和 DataFrame 操作中都支持数据自动对齐功能，同时也支持 `fill_value` 参数指定 `NaN` 值的填充值。

### 常用运算

Series 和 DataFrame 的常用运算方式和 NumPy 中的差不多，这里就不多做介绍了。在 Pandas 中还有一种比较常见的操作是将函数应用到每行或者每一列上面，DataFrame 的 `apply` 方法可以实现此功能，比如想统计每行和每列的极差（最大值和最小值之差）：

![image-20220311170606456](E:\Document\Typora\img\image-20220311170606456.png)

以上代码中，我们定义了 `f` 匿名函数，该匿名函数简单的返回列表的极差，然后首先通过 `df.apply(f)` 应用 `f`, 统计出了每列的极差，接着通过传入 `axis=1` 参数，统计出了每行的极差，如果想将某函数应用到每一个元素上，对于 DataFrame 数据可使用 `df.applymap` 方法，而对于 Series 数据可以使用 `s.map` 方法：

![image-20220311170637328](E:\Document\Typora\img\image-20220311170637328.png)

以上代码中，使所有元素都自增加 1，其结果和 `df1 + 1` 的运算结果相同。

### 常用统计

类似于 NumPy，Series 和 DataFrame 也有各种统计方法，比如求平均值，方差，和等方法，同时通过 `describe` 方法可以得知当前数据的一些常用统计信息：

![image-20220311170803051](E:\Document\Typora\img\image-20220311170803051.png)

可以看到，对于这些统计函数，我们可以指定统计的纬度，和 NumPy 多维数组的统计函数十分相似。默认情况下统计函数按列统计 DataFrame 的信息，但是可以通过参数 `axis=1` 指定按行统计相关信息。 `describe` 方法显示了一些常用的统计信息，具体解释如下：

- `count` 元素值的数量；
- `mean` 平均值；
- `std` 标准差；
- `min` 最小值；
- `25%` 下四分位数；
- `50%` 中位数；
- `75%` 上四分位数；
- `max` 最大值；

### 数据合并和分组

有的时候需要合并两个 DataFrame 数据，合并数据的方式主要有两种，一种简单的进行拼接，另一种是根据列名类像数据库表查询一样进行合并。这两种操作可以分别通过调用 `pandas.concat` 和 `pandas.merge` 方法实现，演示代码如下：

![image-20220315161732295](E:\Document\Typora\img\image-20220315161732295.png)

![image-20220315161743616](E:\Document\Typora\img\image-20220315161743616.png)

上面的代码中，我们使用 `pandas.concat` 函数成功的拼接了两个 DataFrame 数据。有的时候，我们有多个数据集，这些数据集有相同的列，这个时候就可以按照这个列进行合并操作，类似于数据库中的 `join` 操作：

![image-20220315161825849](E:\Document\Typora\img\image-20220315161825849.png)

![image-20220315161834645](E:\Document\Typora\img\image-20220315161834645.png)

上面的代码中我们通过字典创建了两个数据集，可以看到当通过字段创建 DataFrame 数据集的时，键名变成了列名。`df1` 和 `df2` 有共同的列 `course`, 当进行 `merge` 操作的时候 Pandas 会自动安装这列进行合并。合并数据集时，有很多参数可以选择，比如选择在根据哪一列进行合并，合并的方式等，可以通过 `help(pd.merge)` 查看完整的帮助文档。

在 Pandas 中，也支持类似于数据库查询语句 `GROUP BY` 的功能，也就是按照某列进行分组，然后再分组上进行一些计算操作，假如我们有如下的数据集，那么如何计算其中 `user_id` 是 5348 的用户的学习时间呢？

![image-20220315161905158](E:\Document\Typora\img\image-20220315161905158.png)

一种办法是筛选出所有 `user_id` 为 5348 的行，然后进行求和统计，如下：

![image-20220315162111871](E:\Document\Typora\img\image-20220315162111871.png)

![image-20220315162119077](E:\Document\Typora\img\image-20220315162119077.png)

![image-20220315162125607](E:\Document\Typora\img\image-20220315162125607.png)

可以看到我们可以先通过 `df[df['user_id'] == 5348]` 布尔索引筛选出所有的相关行，然后通过结合列筛选功过滤其他列，只剩下时间统计列 (minutes 所在列为学习时间列），最后通过求和运算统计出了学习时间。

我们也可以使用类似于数据库的 `GROUP BY` 功能进行计算，演示代码如下：

![image-20220315162154814](E:\Document\Typora\img\image-20220315162154814.png)

![image-20220315162201022](E:\Document\Typora\img\image-20220315162201022.png)

可以看到，我先过滤列，只剩下了 `user_id` 和 `minutes` 列，然后通过 `groupby` 方法在 `user_id` 列上进行分组并求和，相对于前一种方式，分组求和更加灵活一些。

## dataFrame

 DataFrame 结构大致由 3 部分组成，它们分别是列名称、索引和数据。

![img](https://doc.shiyanlou.com/courses/uid214893-20190531-1559286555222)

+ 筛选数据

[【一日一技】超简单的Pandas数据筛选方法_简说Python的博客-CSDN博客](https://blog.csdn.net/qq_39241986/article/details/104386231)

+ 计数

[dataframe](https://so.csdn.net/so/search?q=dataframe&spm=1001.2101.3001.7020)某列满足特定值的数量

1. df[df["val"]==0].id.count()

2. len(df[df["val"]==0])

+ 替换指定数据

~~~
df.replace("-", np.NaN, inplace=True)
~~~

+ 遍历行/列

~~~
data = pd.read_csv(fileName)
col = data.columns.tolist()
for traits in col:
~~~

+ 读取pandas的某些行列

~~~
print(data.iloc[60:63,0:6]) #前行，后列
~~~

### 找出空值

[python 利用all(),any() 查找存在0、全是0、含缺失值的列_Z pz的博客-CSDN博客](https://blog.csdn.net/wenniewennie/article/details/109387329)

+ 找出有空值的行

~~~
frame3 = pd.DataFrame(data=n, index=index, columns=columns)
print(frame3[frame3.isnull().T.any()])
~~~

+ 找出有空值的列

~~~
frame3 = pd.DataFrame(data=n, index=index, columns=columns)
print(frame3[frame3.isnull().any()])
~~~

![image-20220325095032209](E:\Document\Typora\img\image-20220325095032209.png)

非转置：frame3.isnull().any()，得到的每一列求any()计算的结果，输出为列的Series。

转置：frame3.isnull().T.any()，得到的每一行求any()计算的结果，输出为行的Series。

+ 找出某个位置是否为空

~~~
pd.isnull(data.iloc[i, j]
~~~

+ 清除pandas数据中一行总和为0的数据

`data.apply(np.sum,axis=1) `表示把每一行的数据相加得到一个数值，并返回一个'Series'

~~~
data=data[data.apply(np.sum,axis=1)==0] # data是pandas的DataFrame类型数据,获得值相加为0的数据
return data[data.apply(np.sum, axis=1) != 0]
~~~

+ 清除pandas数据中一行，相比于上一行会率除掉

~~~
plantWithoutChange = data.loc[(data==0).all(axis=1), :]
return data.loc[~(data==0).all(axis=1), :]
~~~

+ 将一样的数据放在一起，写入csv

~~~
data =pd.DataFrame({'a':[1,1,3,4],'b':[1,1,2,3]})
print(data)
indexName = data.index.tolist()
for i,idx in enumerate(indexName):
    row = []
    if i == 0:
        print(data.iloc[i].values)
        continue
    if (data.iloc[0].values == data.iloc[i].values).all():
        print("index is %d is same zero index"%i)
        row = [idx]
        row.extend(data.iloc[i].values)
        print(idx)
        print(data.iloc[i].values)
        print(row)
~~~



+ 删除某一行

用法：DataFrame.drop(labels=None,axis=0, index=None, columns=None, inplace=False)

[Python中pandas dataframe删除一行或一列：drop函数_海晨威的博客-CSDN博客_dataframe drop](https://blog.csdn.net/songyunli1111/article/details/79306639)

~~~
>>>df = pd.DataFrame(np.arange(12).reshape(3,4), columns=['A', 'B', 'C', 'D'])

>>>df

   A   B   C   D

0  0   1   2   3

1  4   5   6   7

2  8   9  10  11

#Drop columns,两种方法等价

>>>df.drop(['B', 'C'], axis=1)

   A   D

0  0   3

1  4   7

2  8  11

>>>df.drop(columns=['B', 'C'])

   A   D

0  0   3

1  4   7

2  8  11

# 第一种方法下删除column一定要指定axis=1,否则会报错
>>> df.drop(['B', 'C'])

ValueError: labels ['B' 'C'] not contained in axis

#Drop rows
>>>df.drop([0, 1])

   A  B   C   D

2  8  9  10  11

>>> df.drop(index=[0, 1])

   A  B   C   D
   
2  8  9  10  11
~~~

+ dropna() 方法过滤任何含有缺失值的行

~~~
>>> import pandas as pd
>>> data = pd.DataFrame([[1.,6.5,3.],[1.],[],[6.5,3.]],index=list('abcd'),columns=list('def'))
>>> data
     d    e    f
a  1.0  6.5  3.0
b  1.0  NaN  NaN
c  NaN  NaN  NaN
d  6.5  3.0  NaN
>>> data.dropna() #任意列只要有一个为空数据，则整行都干掉
     d    e    f
a  1.0  6.5  3.0
~~~

### 找出重复的数据

duplicated()可以被用在DataFrame的三种情况下，分别是pandas.DataFrame.duplicated、pandas.Series.duplicated和pandas.Index.duplicated。他们的用法都类似，前两个会返回一个布尔值的Series，最后一个会返回一个布尔值的numpy.ndarray。

[pandas：找出、删除重复的数据（Python）_william_cheng666的博客-CSDN博客_pandas 找出重复行](https://blog.csdn.net/weixin_43887421/article/details/114926685?spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7.pc_relevant_default&utm_relevant_index=11)

[pandas判断和删除重复duplicated和drop_duplicates_Lavi_qq_2910138025的博客-CSDN博客_.duplicated](https://blog.csdn.net/liuweiyuxiang/article/details/90940160)



**DataFrame.duplicated(subset=None, keep=‘first’)**

**subset**：默认为None，需要标记重复的**标签或标签序列**
**keep**：默认为‘first’，如何标记重复标签

​	**first**：将除第一次出现以外的重复数据标记为True
​	**last**：将除最后一次出现以外的重复数据标记为True
​	**False**：将所有重复的项都标记为True（不管是不是第一次出现）

Series.duplicated(keep=‘first’)
keep：与DataFrame.duplicated的keep相同

Index.duplicated(keep=‘first’)
keep：与DataFrame.duplicated的keep相同

+ read_csv

[详解pandas的read_csv方法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/340441922)

+ 读取时把第一列作为index

~~~
data = pd.read_csv(fileName, index_col = 0)
~~~

+ 打印数据的行列索引

~~~
print(data.columns)  # 行
print(data.index)	 # 列
~~~

+ 读取进去的数据为整型

~~~
dataT = data.astype("int32")
~~~

这个找重复数据，需要考虑空值





## 写入txt

~~~
file_handle=open('1.txt',mode='w')     # 打开txt文件
\#w 只能操作写入 r 只能读取 a 向文件追加
\#w+ 可读可写 r+可读可写 a+可读可追加
\#wb+写入进制数据
\#w模式打开文件，如果而文件中有数据，再次写入内容，会把原来的覆盖掉

file_handle.write('hello word 你好 \n') # write写入
file_handle.write('hello word 你好 \n') # writelines()函数 会将列表中的字符串写入文件中，但不会自动换行，如果需要换行，手动添加换行符
file_handle.close()
~~~

## VCF解析

+ 安装 `pip install PyVCF`
+ 如果版本有问题，安装工具`pip install setuptools`





# 高效爬虫

[Python高效爬虫方案总结 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/115823089)







# py2neo构建图数据库

[neo4j︱与python结合的py2neo使用教程（四）_悟乙己的博客-CSDN博客_py2neo record](https://blog.csdn.net/sinat_26917383/article/details/79901207)

## 基础

+ 创建中文节点

~~~
a = Node("Person", name="Alice")
data = {
'name': 'Amy',
'百粒': 21
}
a.update(data)
g.create(a)
~~~

+ 获得已有节点

~~~
g = Graph("bolt://127.0.0.1:7687", auth=("neo4j", "123456"))
a = Node("Person", name="Alice")
b = Node("Person", name="Ella")
g.create(a)
g.create(b)
ret = g.run("MATCH (n:Person) RETURN n LIMIT 25").data()
n = pd.DataFrame(g.run("MATCH (n:Person) RETURN n")) 
~~~

ret为list类型

dataFrame类型的n如下

![image-20220329171010964](E:\Document\Typora\img\image-20220329171010964.png)

### NodeMatcher找所需节点

py2neoV3有这个函数，py2neoV4没有该函数了，各位注意！！变成这个函数了：class py2neo.matching.NodeMatcher(graph)参考v4 Handbook

NodeMatcher是为更好的查询节点，支持更多的查询条件，比graph更友好

~~~
g = Graph("bolt://127.0.0.1:7687", auth=("neo4j", "123456"))
a = Node("Person", name="Alice")
b = Node("Person", name="Ella")
g.create(a)
g.create(b)
selector = NodeMatcher(g)
nodeA = selector.match('Person').where(name="Alice").first()
nodeB = selector.match('Person').where(name="Ella").first()
rel = Relationship(nodeA,'0/1',nodeB)
g.create(rel)
~~~

`result = selector.match('Person').where(name="Alice").exists()`True和False判断是否存在

+ 返回带连接的节点



# MySQL关系型数据库

## 配置使用

mysql启动，管理员运行cmd

~~~
net start MySQL80
~~~

关闭mysql

~~~
net stop MySQL80
~~~

+ ubuntu上服务器重启
  + `service mysql start`

安装路径：`C:\Program Files\MySQL`，密码：123456

![image-20220415153600870](E:\Document\Typora\img\image-20220415153600870.png)

LOG日志：`DESKTOP-00MR3DJ.err`

实体数据库文件`C:\ProgramData\MySQL\MySQL Server 8.0\Data`

+ 连接报错

~~~
pymysql.err.OperationalError: (1698, “Access denied for user ‘root‘@‘localhost‘“)
~~~

解决方法：

[pymysql.err.OperationalError: (1698, “Access denied for user ‘root‘@‘localhost‘“)_tanhuanzheng的博客-CSDN博客](https://blog.csdn.net/tanhuanzheng/article/details/108960426)

+ ubuntu下安装mysql没有密码

[解决Ubuntu安装Mysql时没有提示设置密码的问题_叫码农就行的博客-CSDN博客_ubuntu安装mysql没有设置密码](https://blog.csdn.net/wei_love_2017/article/details/82313444)

~~~
mysql> update mysql.user set authentication_string=password('123456') where user='root' and Host ='localhost';
mysql> update user set plugin="mysql_native_password"; 
mysql> flush privileges;
mysql> exit:;
~~~

+ 测试数据库连接

~~~
conn = pymysql.connect(host='127.0.0.1', port=3306, user='root',passwd ='123456',db="soybean",charset='utf8')
cursor = conn.cursor()
cursor.execute("SELECT VERSION()")
data = cursor.fetchone()
print("Database version: %s" %data)
conn.close()
~~~

### 配置中文

[MySQL查看并修改当前数据库编码 - 腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1491159)

+ 中文数据输入

设置数据集字符串类型

~~~
alter database rice CHARACTER SET utf8;
~~~

创建表格

~~~
create table GeneIndex (ID int, name varchar(30), plant_num int, loci_table varchar(20),userful_ptg float(4,2),date timestamp,content TEXT);
~~~

数据插入

~~~
sql = 'insert into GeneIndex (ID,name,plant_num,loci_table,content) values(%s,%s,%s,%s,%s)'
cursor.execute(sql,(1,'PlantCH_5k',469,'loci_5k',u'水稻基因数据'))
~~~







### 配置时间





## 基础命令

[经典SQL语句大全_znyyjk的博客-CSDN博客_sql](https://blog.csdn.net/znyyjk/article/details/52717336)

+ 查看所有数据库

~~~
show databases;
~~~

+ 查看数据库中包含的表

~~~
use 数据库名
DESCRIBE 数据库名.表名
~~~

+ 查看当前使用的数据库

~~~
select database();
~~~

+ 创建新的数据库

~~~
create database 数据库名
~~~

+ 查看数据库中包含的表

~~~
USE 数据库名
show tables;
~~~

+ 创建新的表

~~~
CREATE TABLE 表名 (字段1 数据类型,字段2 数据类型[,...][,PRIMARY KEY (主键名)]);
~~~

~~~
create database arts;
use arts;
create table star (id int not null,name char(20) not null,sex char(2),primary key (id));
desc star;
~~~

+ 删除指定数据表

~~~
DROP TABLE 数据库名.表名  // 不用进入库中
DROP table 表名
~~~

+ 插入数据记录

~~~
INSERT INTO 表名(字段1,字段2[,...]) VALUES(字段1的值,字段2的值,...);
例：
create database market;
use market;

create table star (id int(3) not null,name char(20),sex char(2),age int(3),passwd varchar(50), primary key (id));

insert into star (id,name,sex,age,passwd) values(1,'zz','男',18,12345678);

select * from star;
~~~

+ 查询数据记录

~~~
SELECT 字段名1,字段名2[,...] FROM 表名 [WHERE 条件表达式];

例：
select * from star;
select * from star limit 2; // 只显示头两行
select name,sex from star where id=1;
~~~

+ 在数据表中删除指定的数据记录

~~~
DELETE FROM 表名 [WHERE 条件表达式];

例：delete from star where id=6;
select * from star;
~~~

+ 修改表名和表结构

~~~
ALTER TABLE 旧表名 RENAME 新表名;

例：alter table star rename art;
~~~

+ 扩展表结构（增加字段）

~~~
ALTER TABLE 表名 ADD address varchar(50) default '地址不详';
#default ‘地址不详’：表示此字段设置默认值 地址不详；可与 NOT NULL 配合使用

例：
alter table star add address varchar(50) default '地址不详';
~~~

+ 修改字段（列）名，添加唯一键

~~~
ALTER TABLE 表名 CHANGE 旧列名 新列名 数据类型 [unique key];

例：
alter table star change name art_name varchar(20) unique key;
select * from star;
~~~

+ 删除字段

~~~
ALTER TABLE 表名 DROP 字段名;

例：alter table star drop address;
~~~

+ 综合使用

~~~
CREATE DATABASE school;
use school;
create table if not exists info (
id int(4) zerofill primary key auto_increment,				#指定主键的第二种方式
name varchar(10) not null,
cardid int(18) not null unique key,
hobby varchar(50));
~~~

+ 读取第一行

~~~
select * from mytable order by id
~~~



## 查询语句

+ 查询数据行数

  + ~~~
    select count(*) from tableName;
    ~~~

+ 查询数据行数

  + ```
    select count(1) from information_schema.columns where table_name='PlantF5_20k_1';
    ```
  
+ 逆序查询

  + ~~~
    select *  from tablename  order by filename1 desc;
    ~~~

+ 统计不重复的数据个数

  + ~~~
    select count(*) from PlantF5_10k group by plant;
    ~~~

## 计算数量

~~~
>>> Tweet.select().count()
100
>>> Tweet.select().where(Tweet.id > 50).count()
50
~~~

+ 多个条件数量统计

~~~
nums = database.Loci.select().where(database.Loci.tableName == 'loci_20k', database.Loci.chrom == 2).count()
~~~







## 插入数据

+ 插入空数据

在sql语句中插入空数据`insert into test (name,time) values ('hello',null);`

python语句中插入空数据

~~~
sql = 'insert into PlantF3_trait (name,oil_content,protein_content) values(%s,%s,%s)'
cursor.execute(sql,('test', None , 12))
~~~

+ 增加列  注意float,2表示小数点长度，6表示整体长度。

~~~
alter table test add time float(2,6);
~~~

+ 向指定行插入语句（执行一直有问题）

~~~
sql = 'insert into PlantF5_trait (oil_content,protein_content) select %s,%s from PlantF5_trait where exists (select * from PlantF5_trait where PlantF5_trait.name=%s)'
~~~

[MySQL insert or update - 简书 (jianshu.com)](https://www.jianshu.com/p/fb0dcff8a2fd)

以下方法亲测有效，已知name和plant_height添加protein数据输入

![image-20220719094028740](E:\Document\Typora\img\image-20220719094028740.png)









## 修改语句

+ 修改mysql中的数据类型

~~~
conn, cursor = util.connect(dbName)
sql = "alter table " + tableName + " modify column loci varchar(20) not null"
cursor.execute(sql)
~~~

+ 修改pandas的列名

~~~
temp.rename(columns={"type":"loci"},inplace=True)
~~~

用loci代替type列名。



## 数据更新

+ 插入某一列数据

~~~
update PlantCH_trait_hz set tillers_num=11.24 where name='CH001';
~~~







## 使用to_sql

+ 基础使用

~~~
from sqlalchemy import create_engine
engine = create_engine("mysql+pymysql://root:123456@localhost:3306/soybean?charset=utf8")
temp.to_sql(tableName, engine, if_exists='replace',index=False)
~~~

使用这个时候不需要初始化列名称，pandas的列名会直接覆盖。

+ 直接设置列的类型

~~~
df = pd.DataFrame([['a', 1, 2.0, datetime.datetime.now(), True]], columns=['str', 'int', 'float', 'datetime', 'boolean'])
engine = create_engine("mysql+pymysql://root:123456@localhost:3306/test?charset=utf8")
dtypedict = {
'str': NVARCHAR(length=255),
'int': Integer(),
'float': Float()
}
df.to_sql(name="test", con = engine.connect(), if_exists='append',index=False,dtype=dtypedict)
~~~



## 建立索引

~~~
ALTER TABLE PlantF5_20k ADD INDEX (plant);
~~~

建立的索引

![image-20220630150514906](E:\Document\Typora\img\image-20220630150514906.png)



# pymysql

## 基础操作

+ 创建数据库，aynu为数据库名称

~~~
CREATE DATABASE IF NOT EXISTS aynu
DEFAULT CHARACTER SET utf8
DEFAULT COLLATE utf8_general_ci;
~~~

+ 导包

~~~
import pymysql
~~~

+ 连接数据库

~~~
conn = pymysql.connect(host='127.0.0.1', port=3306, user='root',passwd ='123456',db=dbName,charset='utf8')
~~~

+ 获取游标，执行MySQL指令

~~~
cursor = conn.cursor()
~~~

+ 执行sql语句，提交 数据库，关闭连接

~~~
# 执行sql语句
cursor.execute(sql)

try:
	conn.commit()       # 提交数据
except Exception as e:
	conn.rollback()     # 对修改的数据进行场撤销，表示数据回滚
finally:
	# 关闭游标
	cursor.close()

# 关闭连接
conn.close()
~~~

## sql语句

+ 创建表格

~~~
cursor.execute('DROP TABLE IF EXISTS `'+ tablename +'`')	// 如果存在表格就舍弃
sql = 'CREATE TABLE `'+ tablename +'` (       ID varchar(20) not null primary key,            type int not null            )'
cursor.execute(sql)
~~~

反引号是对

+ 使用三个引号

为避免使用转义换行符 \n，通常会用在定义SQL语句的表达式中没有变量的时候，例如：

~~~
# SQL建表语句
sql_create_table = """CREATE TABLE CUSTOMER (
	FULL_NAME  CHAR(20) NOT NULL,
	AGE INT,
	SEX CHAR(1),
	BALANCE FLOAT )"""

cur.execute(sql_create_table)

# SQL 插入语句
sql_insert = """INSERT INTO CUSTOMER (FULL_NAME,
	AGE, SEX, BALANCE)
	VALUES ('Mac Mohan', 20, 'M', 2000)"""
~~~

+ [mysql中引号的用法（反引号``，单引号''，双引号""） - 坚持一点点 - 博客园 (cnblogs.com)](https://www.cnblogs.com/jcydd/p/11469879.html)
+ 反引号：区分MYSQL的保留字与普通字符而引入的符号。

### 分类计数

+ 计算每个染色体上位点数量

~~~
    sql = "select chrom,count(*) from `"+ info['table']+"` group by chrom"
    count = myconn.select(sql)
    eachChrom = []
    for chroms in count:
        keys = "chr" + str(chroms[0])
        temp = {"name":keys,"value":chroms[1]}
        eachChrom.append(temp)
~~~



## 检索结果生成list

~~~
sql = 'select name from PhenotypeIndex'
ret = myconn.select(sql)
ret = list(chain.from_iterable(ret))
~~~

ret = ['F3_trait', 'F4_trait', 'F5_trait']





### 插入变量

~~~
import pymysql
conn = pymysql.connect(host='localhost',user='root',password='1234',database='pymysql_demo',port=3306)
cursor = conn.cursor()
 
#若id选择自动递增并为主键，可以设为null,让其自动增长。
sql = """
insert into user(id,username,age,password) value(null,%s,%s,%s)
"""
username = 'Lily'
age = 20
password = '666666'
cursor.execute(sql,(username,age,password))
conn.commit()
 
conn.close()
~~~

+ 建立表单

~~~
conn = pymysql.connect(host='127.0.0.1', port=3306, user='root',passwd ='123456',db="Soybean",charset='utf8')
cursor = conn.cursor()
sql = 'CREATE TABLE `'+ plantIndexTable +'` (plant varchar(20) not null primary key,  tablename varchar(20) not null,tbcolumn int not null)'
~~~

- 插入变量

~~~
conn = pymysql.connect(host='127.0.0.1', port=3306, user='root',passwd ='123456',db="Soybean",charset='utf8')
cursor = conn.cursor()
sql = "insert into " + plantIndexTable + "(plant,tablename,tbcolumn) values(%s,%s,%s)"
 cursor.execute(sql,("A-F5-14062-1","F5_20k_0",columnIdx))
~~~

关于`%s` ：

​	MySQLdb的字符串格式化不是标准的python的字符串格式化，应当一直使用%s用于字符串格式化

[python mysql插入数据报错：TypeError: %d format: a number is required, not str_瞭望天空的博客-CSDN博客](https://blog.csdn.net/u010700335/article/details/75090457)

- 更新一至多个变量

~~~
sql = "insert into " + plantIndexTable + "(plant,tablename,tbcolumn) values(%s,%s,%s) on duplicate key update tablename=%s,tbcolumn=%s"
cursor.execute(sql,("A-F5-14062-1","F5_20k_0",column, "F5_20k_1", column))
~~~







- **`ON DUPLICATE KEY UPDATE`** 只会对所匹配的第一行进行update,
- **`REPLACE INTO`** 会对所有匹配行进行delete, insert

+ 根据条件更新变量

~~~
sql = 'UPDATE student SET stu_score = (%s) WHERE student_id = (%s)'
~~~







# peewee

[Python Peewee 教程|极客教程 (geek-docs.com)](https://geek-docs.com/python/python-tutorial/python-peewee.html)

[Peewee字段类|酷客网 (coolcou.com)](https://www.coolcou.com/peewee/peewee-tutorials/peewee-field-class.html)

[peewee的使用 - 杨是杨柳的柳 - 博客园 (cnblogs.com)](https://www.cnblogs.com/willow-yang/p/14644599.html)

[peewee基本使用 - 檐夏 - 博客园 (cnblogs.com)](https://www.cnblogs.com/yxi-liu/p/8514763.html)

[查询 — peewee 3.14.4 文档 (osgeo.cn)](https://www.osgeo.cn/peewee/peewee/querying.html)

[python轻量级orm框架 peewee常用功能速查 - 金色旭光 - 博客园 (cnblogs.com)](https://www.cnblogs.com/goldsunshine/p/15259246.html)

## 通过已有的数据库的表生成model

比如我现在有一张已经创建好的表 caiji表

执行

python -m pwiz -e mysql -H localhost -p 3306 -u 数据库用户名 -P 数据库密码 -t 表名(table name) 库名(database name) > 要生成的python文件名称.py
-u 后面是你的数据库的登陆用的用户名，通常为root

-P 是你的数据库登陆的时候使用的密码，我本地数据库密码是 abc123

-t 是你要转换的表的名字，这里是 caiji 表 ，后面加一个空格，再写上表所在的数据库的名字，假如我的数据库叫 mytest 数据库

>  后面是你要生成的python的文件名，这个是自定义的，为了方便项目管理，我这里就用 article_caiji.py 来命名

~~~
python -m pwiz -e mysql -H localhost -p 3306 -u root -P abc123 -t caiji mytest > article_caiji.py
~~~



## 创建

[peewee基本使用 - 檐夏 - 博客园 (cnblogs.com)](https://www.cnblogs.com/yxi-liu/p/8514763.html)

`datetime.datetime.strptime`可以将字符串转为时间类型

~~~
st = "2021-4-15 10:00:00"
database.GeneIndex.create(id=1, name='F5_20k', plantNum=999, lociTable='loci_10k', generation = 'F5', usefulPtg=94.26, date=datetime.datetime.strptime(st, "%Y-%m-%d %H:%M:%S"), content='F5世代基因')
~~~

+ 允许为空

~~~
generation = CharField(null = True)
~~~

+ 设置主键

~~~
name = CharField(primary_key=True)
~~~

如果不设置id和主键会自动设置id作为主键并自动生成

+ 设置不能重复

~~~
name = CharField(unique=True)
~~~

即`unique_key`并同时生成索引

+ 设置char长度

~~~
REF = CharField(max_length=1)
~~~



## 导入

+ 单个导入数据

~~~
database.Loci.create(chrom=loci['chrom'],pos=loci['pos'],name=loci['name'],REF=loci['REF'],ALT=loci['ALT'],table='loci_20k')
~~~



+ 批量导入数据

将数据用pandas输入，

~~~
# 最快的插入方法，想在快估计只能换模块了
# peewee性能限制，无法一次插入太多条，因此根据自己的情况调整，一般不能比100更多，出现插入出错的情况，可以适当减少该数值
with database.db.atomic():
    for i in range(0, len(df), 100):
        database.Loci.insert_many(df[i:i+100].to_dict('records')).execute()
~~~



## 修改

~~~
row=User.get(User.name=="Amar")
print ("name: {} age: {}".format(row.name, row.age))
row.age=25
row.save()
~~~

或者使用update()

~~~
qry=User.update({User.age:25}).where(User.age>20)
print (qry.sql())
qry.execute()
~~~





## 读取

[Python折腾数据库（一）peewee - 简书 (jianshu.com)

[[【Python 库】轻量级 ORM 框架 peewee 用法详解之——增删改查 - 丹枫无迹 - 博客园 (cnblogs.com)](https://www.cnblogs.com/gl1573/p/10380793.html)](https://www.jianshu.com/p/84e667320ab3)

+ 读取单个数据

~~~
k = database.User.select().where(database.User.username == 'lixiaoyuan').get()
~~~

+ 获取列表数据

~~~
for tablelist in database.TableTraitList.select().where(database.TableTraitList.tablename == 'F5_trait'):
    print(tablelist.trait)
~~~

+ 批量读取全部数据

~~~
database.LociIndex.select()
~~~

+  读取全部数据并转为字典

~~~】
database.LociIndex.select().dicts()
~~~

+ 查询数据是否存在

如果当获取的结果不存在时，不想报错，可以使用 `Model.get_or_none()` 方法，会返回 `None`，参数和 `get` 方法一致。





+ 获取查询数据

`Model.get()` 方法检索与给定查询匹配的单个实例。

~~~
p1 = Person.get(Name='张三')
~~~



+ 将查询转换为Pandas DataFrame

~~~
df = pd.DataFrame(list(query.dicts()))
~~~





# Pandas

+ 根据要求进行数据替换

[Pandas: 根据一列的条件来替换另一列的值 - 简书 (jianshu.com)](https://www.jianshu.com/p/6e0a62fc1a83)

根据类型对某行数据进行替换

~~~
df['REF']= df['REF'].mask(df['type']=='drop',df['dropbase'])
~~~

+ 替换空值

[ Python pandas 替换指定数据_永远在减肥永远110的的小潘的博客-CSDN博客_pandas替换指定的值](https://blog.csdn.net/p1306252/article/details/114880994)

+ 插入新的列并指定位置

~~~
newData = df.apply(lambda df:mergeString(df['chrom'],df['pos']), axis=1)
df.insert(0,column='loci',value=newData)
~~~

+ 筛选符合要求的数据

~~~
geneStr = data[(data['chrom'] == chromStr) & (data['begin'] <= pos) & (data['end'] >= pos)]['gene'].tolist()
~~~

+ 计算符合要求的条件个数

~~~
cnt1 = (gene == 'NN').sum()
~~~

~~~
((data['chrom'] == chromStr) & (data['begin'] <= pos) & (data['end'] >= pos)).sum()
~~~

+ 计算全部行列符合要求的个数

~~~
df_bool_not = ~(df == 'CA')
print(df_bool_not)
#    name   age  state  point
# 0  True  True   True   True
# 1  True  True  False   True
# 2  True  True  False   True
# 3  True  True   True   True
# 4  True  True  False   True
# 5  True  True   True   True

print(df_bool_not.sum())
# name     6
# age      6
# state    3
# point    6
# dtype: int64

print(df_bool_not.sum(axis=1))
# 0    4
# 1    3
# 2    3
# 3    4
# 4    3
# 5    4
# dtype: int64

print(df_bool_not.values.sum())
# 21
~~~

+ 计算基因的无效数值比例

~~~
genes = pd.read_csv('newricegene.csv',index_col='loci')
total = genes.columns.size * genes.index.size
genes = genes.astype("int8")
cnt = (genes==-1).values.sum()
print(cnt * 100/total)
~~~

+ 遍历每一行并进行数据替换

~~~
for index,row in gene.iterrows():
	ref = base.loc[index,'REF']
	alt = base.loc[index,'ALT']
	he = gt_he[ref+alt]
	gene.loc[index].replace('0.0',ref,inplace=True)
	gene.loc[index].replace('1.0',he,inplace=True)
	gene.loc[index].replace('2.0',alt,inplace=True)
~~~



## 数据遍历

+ 按照行进行遍历

~~~
for index,row in gene.iterrows():
    ref = base.loc[index,'REF']
    alt = base.loc[index,'ALT']
~~~

+ 按照列进行遍历

~~~
for plant,line in df.items():
~~~

+ 遍历series

~~~
for key,value in line.items():
~~~

## pandas初始化

+ 用列进行初始化，指定列名

~~~
cmpPd = pd.DataFrame(columns=['plantOne', 'plantTwo', 'same', 'invalid', 'total'])
~~~



## csv导入导出

+ 对csv文件的读写

~~~
df = pd.read_csv('Cultivar_600w.csv',index_col=0)
df.replace(np.NaN, -1, inplace=True)
df = df.astype("int8")
df = df.T
df.to_csv('PZ_600w.csv',index=False, header=0, sep=' ')
~~~

读取时，设置index_col会将第一列转为index。

replace可以把NaN转为-1。

df.astype将默认float类型转为int8类型。

数据转存csv格式时，设置index=false即列不输出index，header不输出column，sep设置分隔符。



## 增加行/列

添加行有 **df.loc [] 以及 df.append ()** 这两种方法

+ 增加列

`insert(loc, column, value, allow_duplicates=False)`

loc： 插入列的索引。第一列是 0。
column： 赋予新列的名称。
value： 新列的值数组。
allow_duplicates： 是否允许新列名匹配现有列名。默认值为假。

~~~
df.insert(loc=len(df.columns), column='type',value=1)
~~~

或者`df['type'] = 1`

+ 增加第一列作为索引

~~~
df = pd.read_csv('loci_10k.csv')
nums = df.index.size
df.insert(0,'index', range(1, nums+1))
df.to_csv('loci_20k_new.csv',index=False)
~~~

+ 根据已有数据填充新列数据

~~~
df['snpPtg'] = df.apply(lambda df:calculatePtg(df['change_loci'],df['lociNum']),axis=1)
~~~

+ 删除列

~~~
 df.drop('change_loci',axis=1,inplace=True)
~~~







# Matplotlib数据可视化

## 方法

~~~
from matplotlib import pyplot as plt
~~~

`pyplot` 模块中 `pyplot.plot` 方法是用来绘制折线图的。你应该会很容易联想到，更改后面的方法类名就可以更改图形的样式。的确，在 Matplotlib 中，大部分图形样式的绘制方法都存在于 `pyplot` 模块中。例如：

| 方法                               | 含义           |
| ---------------------------------- | -------------- |
| `matplotlib.pyplot.angle_spectrum` | 绘制电子波谱图 |
| `matplotlib.pyplot.bar`            | 绘制柱状图     |
| `matplotlib.pyplot.barh`           | 绘制直方图     |
| `matplotlib.pyplot.broken_barh`    | 绘制水平直方图 |
| `matplotlib.pyplot.contour`        | 绘制等高线图   |
| `matplotlib.pyplot.errorbar`       | 绘制误差线     |
| `matplotlib.pyplot.hexbin`         | 绘制六边形图案 |
| `matplotlib.pyplot.hist`           | 绘制柱形图     |
| `matplotlib.pyplot.hist2d`         | 绘制水平柱状图 |
| `matplotlib.pyplot.pie`            | 绘制饼状图     |
| `matplotlib.pyplot.quiver`         | 绘制量场图     |
| `matplotlib.pyplot.scatter`        | 散点图         |
| `matplotlib.pyplot.specgram`       | 绘制光谱图     |

`matplotlib.pyplot.plot(*args, **kwargs)` 方法严格来讲可以绘制线形图或者样本标记。其中，`*args` 允许输入单个 y*y* 值或 x, y*x*,*y* 值。

例如，我们这里绘制一张自定义 x, y*x*,*y* 的正弦曲线图。

```python
import numpy as np  # 载入数值计算模块

# 在 -2PI 和 2PI 之间等间距生成 1000 个值，也就是 X 坐标
X = np.linspace(-2*np.pi, 2*np.pi, 1000)
# 计算 y 坐标
y = np.sin(X)

# 向方法中 `*args` 输入 X，y 坐标
plt.plot(X, y)

```

正弦曲线就绘制出来了。但值得注意的是，`pyplot.plot` 在这里绘制的正弦曲线，实际上不是严格意义上的曲线图，而在两点之间依旧是直线。这里看起来像曲线是因为样本点相互挨得很近。

柱形图 `matplotlib.pyplot.bar(*args, **kwargs)` 大家应该都非常了解了。这里，我们直接用上面的代码，仅把 `plt.plot(X, y)` 改成 `plt.bar(X, y)` 试一下。

```python
plt.bar([1, 2, 3], [1, 2, 3])

```

散点图 `matplotlib.pyplot.scatter(*args, **kwargs)` 就是呈现在二维平面的一些点，这种图像的需求也是非常常见的。比如，我们通过 GPS 采集的数据点，它会包含经度以及纬度两个值，这样的情况就可以绘制成散点图。

```python
# X,y 的坐标均有 numpy 在 0 到 1 中随机生成 1000 个值
X = np.random.ranf(1000)
y = np.random.ranf(1000)
# 向方法中 `*args` 输入 X，y 坐标
plt.scatter(X, y)

```

饼状图 `matplotlib.pyplot.pie(*args, **kwargs)` 在有限列表以百分比呈现时特别有用，你可以很清晰地看出来各类别之间的大小关系，以及各类别占总体的比例。

```python
plt.pie([1, 2, 3, 4, 5])

```

量场图 `matplotlib.pyplot.quiver(*args, **kwargs)` 就是由向量组成的图像，在气象学等方面被广泛应用。从图像的角度来看，量场图就是带方向的箭头符号。

```python
X, y = np.mgrid[0:10, 0:10]
plt.quiver(X, y)

```

中学学习地理的时候，我们就知道等高线了。等高线图 `matplotlib.pyplot.contourf(*args, **kwargs)` 是工程领域经常接触的一类图，它的绘制过程稍微复杂一些。

```python
# 生成网格矩阵
x = np.linspace(-5, 5, 500)
y = np.linspace(-5, 5, 500)
X, Y = np.meshgrid(x, y)
# 等高线计算公式
Z = (1 - X / 2 + X ** 3 + Y ** 4) * np.exp(-X ** 2 - Y ** 2)

plt.contourf(X, Y, Z)
```

## 定义图形样式

上面，我们绘制了简单的基础图形，但这些图形都不美观。你可以通过更多的参数来让图形变得更漂亮。

我们已经知道了，线形图通过 `matplotlib.pyplot.plot(*args, **kwargs)` 方法绘出。其中，`args` 代表数据输入，而 `kwargs` 的部分就是用于设置样式参数了。

二维线形图 [ *包含的参数*](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.plot.html) 超过 40 余项，其中常用的也有 10 余项，选取一些比较有代表性的参数列举如下：

| 参数         | 含义                            |
| ------------ | ------------------------------- |
| `alpha=`     | 设置线型的透明度，从 0.0 到 1.0 |
| `color=`     | 设置线型的颜色                  |
| `fillstyle=` | 设置线型的填充样式              |
| `linestyle=` | 设置线型的样式                  |
| `linewidth=` | 设置线型的宽度                  |
| `marker=`    | 设置标记点的样式                |
| ……           | ……                              |

至于每一项参数包含的设置选项，大家需要通过 [ *官方文档*](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) 详细了解。

下面，我们重新绘制一个三角函数图形。

```python
# 在 -2PI 和 2PI 之间等间距生成 1000 个值，也就是 X 坐标
X = np.linspace(-2 * np.pi, 2 * np.pi, 1000)
# 计算 sin() 对应的纵坐标
y1 = np.sin(X)
# 计算 cos() 对应的纵坐标
y2 = np.cos(X)

# 向方法中 `*args` 输入 X，y 坐标
plt.plot(X, y1, color='r', linestyle='--', linewidth=2, alpha=0.8)
plt.plot(X, y2, color='b', linestyle='-', linewidth=2)

```

散点图也是相似的，它们的很多样式参数都是大同小异，需要大家阅读 [ *官方文档*](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) 详细了解。

| 参数          | 含义                 |
| ------------- | -------------------- |
| `s=`          | 散点大小             |
| `c=`          | 散点颜色             |
| `marker=`     | 散点样式             |
| `cmap=`       | 定义多类别散点的颜色 |
| `alpha=`      | 点的透明度           |
| `edgecolors=` | 散点边缘颜色         |

```python
# 生成随机数据
x = np.random.rand(100)
y = np.random.rand(100)
colors = np.random.rand(100)
size = np.random.normal(50, 60, 10)

plt.scatter(x, y, s=size, c=colors)  # 绘制散点图

```

饼状图通过 `matplotlib.pyplot.pie()` 绘出。我们也可以进一步设置它的颜色、标签、阴影等各类样式。下面就绘出一个示例。

```python
label = 'Cat', 'Dog', 'Cattle', 'Sheep', 'Horse'  # 各类别标签
color = 'r', 'g', 'r', 'g', 'y'  # 各类别颜色
size = [1, 2, 3, 4, 5]  # 各类别占比
explode = (0, 0, 0, 0, 0.2)  # 各类别的偏移半径
# 绘制饼状图
plt.pie(size, colors=color, explode=explode,
        labels=label, shadow=True, autopct='%1.1f%%')
# 饼状图呈正圆
plt.axis('equal')
```

## 组合图形样式

上面演示了单个简单图像的绘制。实际上，我们往往会遇到将几种类型的一样的图放在一张图内显示，也就是组合图的绘制。其实很简单，你只需要将所需图形的代码放置在一起就可以了，比如绘制一张包含柱形图和折线图的组合图。

```python
x = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]
y_bar = [3, 4, 6, 8, 9, 10, 9, 11, 7, 8]
y_line = [2, 3, 5, 7, 8, 9, 8, 10, 6, 7]

plt.bar(x, y_bar)
plt.plot(x, y_line, '-o', color='y')
```

当然，并不是任何的代码放在一起都是组合图。上面，两张图的横坐标必须共享，才能够被 Matplotlib 自动判断为组合图效果。

## 定义图形位置

在图形的绘制过程中，你可能需要调整图形的位置，或者把几张单独的图形拼接在一起。此时，我们就需要引入 `plt.figure` 图形对象了。

下面，我们绘制一张自定义位置的图形。

```python
x = np.linspace(0, 10, 20)  # 生成数据
y = x * x + 2

fig = plt.figure()  # 新建图形对象
axes = fig.add_axes([0.5, 0.5, 0.8, 0.8])  # 控制画布的左, 下, 宽度, 高度
axes.plot(x, y, 'r')
```

上面的绘图代码中，你可能会对 `figure` 和 `axes` 产生疑问。Matplotlib 的 API 设计的非常符合常理，在这里，`figure` 相当于绘画用的画板，而 `axes` 则相当于铺在画板上的画布。我们将图像绘制在画布上，于是就有了 `plot`，`set_xlabel` 等操作。

![img](https://doc.shiyanlou.com/document-uid214893labid7506timestamp1543470230951.png)

借助于图形对象，我们可以实现大图套小图的效果。

```python
fig = plt.figure()  # 新建画板
axes1 = fig.add_axes([0.1, 0.1, 0.8, 0.8])  # 大画布
axes2 = fig.add_axes([0.2, 0.5, 0.4, 0.3])  # 小画布

axes1.plot(x, y, 'r')  # 大画布
axes2.plot(y, x, 'g')  # 小画布

```

显示如下

![image-20220321093516990](E:\Document\Typora\img\image-20220321093516990.png)



上面的绘图代码中，你已经学会了使用 `add_axes()` 方法向我们设置的画板 `figure` 中添加画布 `axes`。在 Matplotlib 中，还有一种添加画布的方式，那就是 `plt.subplots()`，它和 `axes` 都等同于画布。

```python
fig, axes = plt.subplots()
axes.plot(x, y, 'r')
```

借助于 `plt.subplots()`，我们就可以实现子图的绘制，也就是将多张图按一定顺序拼接在一起。

```python
fig, axes = plt.subplots(nrows=1, ncols=2)  # 子图为 1 行，2 列
for ax in axes:
    ax.plot(x, y, 'r')
```

通过设置 `plt.subplots` 的参数，可以实现调节画布尺寸和显示精度。

```python
fig, axes = plt.subplots(
    figsize=(16, 9), dpi=50)  # 通过 figsize 调节尺寸, dpi 调节显示精度
axes.plot(x, y, 'r')
```

## 规范绘图方式

上面，我们已经入门了 Matplotlib 的绘图方法。由于 Matplotlib 的灵活性，很多方法都可以画出图形来。但为了避免「想怎么画，就怎么画」的问题，我们需要根据自己的习惯，约定一套比较规范的绘图方法。

首先，任何图形的绘制，都建议通过 `plt.figure()` 或者 `plt.subplots()` 管理一个完整的图形对象。而不是简单使用一条语句，例如 `plt.plot(...)` 来绘图。

管理一个完整的图形对象，有很多好处。在图形的基础上，给后期添加图例，图形样式，标注等预留了很大的空间。除此之外。代码看起来也更加规范，可读性更强。

接下来，我们就通过几组例子来演示规范的绘图方法。

### 添加图标题、图例

绘制包含图标题、坐标轴标题以及图例的图形，举例如下

```python
fig, axes = plt.subplots()

axes.set_xlabel('x label')  # 横轴名称
axes.set_ylabel('y label')
axes.set_title('title')  # 图形名称

axes.plot(x, x**2)
axes.plot(x, x**3)
axes.legend(["y = x**2", "y = x**3"], loc=0)  # 图例
```

图例中的 `loc` 参数标记图例位置，`1，2，3，4` 依次代表：右上角、左上角、左下角，右下角；`0` 代表自适应

### 线型、颜色、透明度

在 Matplotlib 中，你可以设置线的颜色、透明度等其他属性。

```python
fig, axes = plt.subplots()

axes.plot(x, x+1, color="red", alpha=0.5)
axes.plot(x, x+2, color="#1155dd")
axes.plot(x, x+3, color="#15cc55")

```

而对于线型而言，除了实线、虚线之外，还有很多丰富的线型可供选择。

```python
fig, ax = plt.subplots(figsize=(12, 6))

# 线宽
ax.plot(x, x+1, color="blue", linewidth=0.25)
ax.plot(x, x+2, color="blue", linewidth=0.50)
ax.plot(x, x+3, color="blue", linewidth=1.00)
ax.plot(x, x+4, color="blue", linewidth=2.00)

# 虚线类型
ax.plot(x, x+5, color="red", lw=2, linestyle='-')
ax.plot(x, x+6, color="red", lw=2, ls='-.')
ax.plot(x, x+7, color="red", lw=2, ls=':')

# 虚线交错宽度
line, = ax.plot(x, x+8, color="black", lw=1.50)
line.set_dashes([5, 10, 15, 10])

# 符号
ax.plot(x, x + 9, color="green", lw=2, ls='--', marker='+')
ax.plot(x, x+10, color="green", lw=2, ls='--', marker='o')
ax.plot(x, x+11, color="green", lw=2, ls='--', marker='s')
ax.plot(x, x+12, color="green", lw=2, ls='--', marker='1')

# 符号大小和颜色
ax.plot(x, x+13, color="purple", lw=1, ls='-', marker='o', markersize=2)
ax.plot(x, x+14, color="purple", lw=1, ls='-', marker='o', markersize=4)
ax.plot(x, x+15, color="purple", lw=1, ls='-',
        marker='o', markersize=8, markerfacecolor="red")
ax.plot(x, x+16, color="purple", lw=1, ls='-', marker='s', markersize=8,
        markerfacecolor="yellow", markeredgewidth=2, markeredgecolor="blue")

```

### 画布网格、坐标轴范围

有些时候，我们可能需要显示画布网格或调整坐标轴范围。设置画布网格和坐标轴范围。这里，我们通过指定 `axes[0]` 序号，来实现子图的自定义顺序排列。

```python
fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# 显示网格
axes[0].plot(x, x**2, x, x**3, lw=2)
axes[0].grid(True)

# 设置坐标轴范围
axes[1].plot(x, x**2, x, x**3)
axes[1].set_ylim([0, 60])
axes[1].set_xlim([2, 5])

```

除了折线图，Matplotlib 还支持绘制散点图、柱状图等其他常见图形。下面，我们绘制由散点图、梯步图、条形图、面积图构成的子图。

```python
n = np.array([0, 1, 2, 3, 4, 5])

fig, axes = plt.subplots(1, 4, figsize=(16, 5))

axes[0].scatter(x, x + 0.25*np.random.randn(len(x)))
axes[0].set_title("scatter")

axes[1].step(n, n**2, lw=2)
axes[1].set_title("step")

axes[2].bar(n, n**2, align="center", width=0.5, alpha=0.5)
axes[2].set_title("bar")

axes[3].fill_between(x, x**2, x**3, color="green", alpha=0.5)
axes[3].set_title("fill_between")

```

## 图形标注方法

当我们绘制一些较为复杂的图像时，阅读对象往往很难全面理解图像的含义。而此时，图像标注往往会起到画龙点睛的效果。图像标注，就是在画面上添加文字注释、指示箭头、图框等各类标注元素。

Matplotlib 中，文字标注的方法由 `matplotlib.pyplot.text()` 实现。最基本的样式为 `matplotlib.pyplot.text(x, y, s)`，其中 x, y 用于标注位置定位，s 代表标注的字符串。除此之外，你还可以通过 `fontsize=` , `horizontalalignment=` 等参数调整标注字体的大小，对齐样式等。

下面，我们举一个对柱形图进行文字标注的示例。

```python
fig, axes = plt.subplots()

x_bar = [10, 20, 30, 40, 50]  # 柱形图横坐标
y_bar = [0.5, 0.6, 0.3, 0.4, 0.8]  # 柱形图纵坐标
bars = axes.bar(x_bar, y_bar, color='blue', label=x_bar, width=2)  # 绘制柱形图
for i, rect in enumerate(bars):
    x_text = rect.get_x()  # 获取柱形图横坐标
    y_text = rect.get_height() + 0.01  # 获取柱子的高度并增加 0.01
    plt.text(x_text, y_text, '%.1f' % y_bar[i])  # 标注文字

```

除了文字标注之外，还可以通过 `matplotlib.pyplot.annotate()` 方法向图像中添加箭头等样式标注。接下来，我们向上面的例子中增添一行增加箭头标记的代码。

```python
fig, axes = plt.subplots()

bars = axes.bar(x_bar, y_bar, color='blue', label=x_bar, width=2)  # 绘制柱形图
for i, rect in enumerate(bars):
    x_text = rect.get_x()  # 获取柱形图横坐标
    y_text = rect.get_height() + 0.01  # 获取柱子的高度并增加 0.01
    plt.text(x_text, y_text, '%.1f' % y_bar[i])  # 标注文字

    # 增加箭头标注
    plt.annotate('Min', xy=(32, 0.3), xytext=(36, 0.3),
                 arrowprops=dict(facecolor='black', width=1, headwidth=7))

```

上面的示例中，`xy=()` 表示标注终点坐标，`xytext=()` 表示标注起点坐标。在箭头绘制的过程中，`arrowprops=()` 用于设置箭头样式，`facecolor=` 设置颜色，`width=` 设置箭尾宽度，`headwidth=` 设置箭头宽度，可以通过 `arrowstyle=` 改变箭头的样式。

## 兼容 MATLAB 代码风格接口

 *提示*：本部分内容适合于之前有 MATLAB 基础的用户了解，其他读者可以直接跳过。

相信很多学理工科的同学都使用过 MATLAB，它是一种用于算法开发、数据可视化、数据分析以及数值计算的高级技术计算语言和交互式环境。而在 Matplotlib 中，也提供了和 MATLAB 相似的 API。对于使用过 MATLAB 的同学而言，这将是入门 Matplotlib 最快的方式。

使用 Matplotlib 提供的兼容 MATLAB API，需要导入 pylab 模块：

```python
from matplotlib import pylab

```

使用 NumPy 生成随机数据：

```python
x = np.linspace(0, 10, 20)
y = x * x + 2

```

只需要 1 句命令就可以完成绘图：

```python
pylab.plot(x, y, 'r')  # 'r' 代表 red

```

如果我们要绘制子图，就可以使用 `subplot` 方法绘制子图：

```python
pylab.subplot(1, 2, 1)  # 括号中内容代表（行，列，索引）
pylab.plot(x, y, 'r--')  # ‘’ 中的内容确定了颜色和线型

pylab.subplot(1, 2, 2)
pylab.plot(y, x, 'g*-')

```

使用兼容 MATLAB 风格的 API 的好处在于，如果熟悉 MATLAB，那么将很快上手使用 Python 绘图。不过，除了一些简单的图形之外，并不鼓励使用兼容 MATLAB 的 API。

实验更加建议学习和使用前面介绍的 Matplotlib 提供的面向对象 API，它更加强大和好用。




# 实验楼课程
## HTTP 协议及 API 采集数据 
请求方式 	说明
GET 	向指定的资源发出请求，用于读取数据
HEAD 	类似于 GET 请求，但不会返回具体内容，用于获取报头
POST 	向指定资源提交新数据或修改已有数据
PUT 	向指定资源上传其最新内容
DELETE 	向指定资源请求删除相关内容
CONNECT 	通常用于 SSL 加密服务器的链接
OPTIONS 	使服务器传回该资源所支持的所有 HTTP 请求方法
TRACE 	回显服务器收到的请求，主要用于测试或诊断

+ 第三方数据提供商
[第三方数据提供商](https://aqicn.org/city/beijing/)
[ API 的调用方式](https://aqicn.org/api)
根据[文档说明](https://aqicn.org/json-api/doc/)，如果要获取某个城市的 PM2.5 数据，我们的请求方法如下：
~~~
GET https://api.waqi.info/feed/:city/?token=:token
~~~
其中，参数：

    city：城市拼音缩写或代码。
    token：私有 API 令牌。
我们已经为大家申请好了一个 token 供实验学习使用：token=d9c0f3c71143407d61c900d9dbb450489303e7e8。
接下来，就可以按照 API 文档中介绍的 HTTP 请求方法，来获取数据。Python 中，我们通常使用 requests 模块建立 HTTP 连接。

### 使用 GET 方法请求数据
~~~
import requests
raw = requests.get(

    'http://api.waqi.info/feed/chengdu/?token=d9c0f3c71143407d61c900d9dbb450489303e7e8')

raw
<Response [200]>
~~~
如上所示，我们可以将请求地址和参数组合成一个 URL，然后通过 GET 方法完成请求。一般情况下，请求地址和参数之间通过 ? 连接，参数与参数之间会通过 & 连接，当然这里只有 token 一个参数所以不存在 &。

上面返回 Response [200] 是 HTTP 请求状态码。HTTP 状态码（英语：HTTP Status Code）是用以表示 HTTP 协议响应状态的 3 位数字代码。不同的代码代表不同的含有，常见代码如下：
状态码 	含义
200 	请求成功
401 	请求未授权
404 	请求的资源不存在
500 	内部服务器错误

 raw.json() 返回了 JSON 样式的数据，而数据的类型却为 dict，而 pd.read_json() 只能读取 JSON 数据（字符串类型）。
读取json数据
~~~
pd.DataFrame(raw.json())
pd.read_json(json.dumps(raw.json()))
~~~


### 获取非公开API数据

页面调出浏览器的「开发者工具」，你可以通过鼠标右键点击打开「检查」。
接下来，切换到开发者工具（DevTools）的网络（Network）面板，刷新页面后就能捕捉到浏览器与服务器之间的全部通信。

然后，在 Filter 导航中选中 XHR 选项,用来过滤无关的 HTTP 请求。此时，点击评论「下一页」执行翻页，Network 就能捕获评论数据 JSON。

如果你仔细观察上面的链接 https://www.lanqiao.cn/api/v2/comments/?page_size=15&topic_id=1&topic_type=course 就会发现，链接中有一个 page_size=15 的参数。其实，API 一般在设计时都是有规律的，你可以将其改为 page_size=30 试一试。


    #更改参数 page=2
    linux_raw = requests.get(
        'https://www.lanqiao.cn/api/v2/comments/?page_size=30&topic_id=1&topic_type=course')
    linux_df = pd.DataFrame(linux_raw.json().get('results'))
    linux_df.content

实际上，通过 API 获取数据的关键在于三点：

    找到能提供相应 API 的数据源。
    仔细阅读 API 请求文档，按数据源要求调用相应接口。
    使用 Pandas，JSON 等模块对原始数据进行解析。

[Public APIs公开API合集](https://github.com/toddmotto/public-apis)

## 数据预处理

### 缺失值处理

当我们使用 Pandas 定位缺失数据时，通常会使用 isnull() 或者 notnull() 两种方法。二者均会返回布尔值，当我们使用 isnull() 时，返回 True 即代表是缺失值。

    df.isnull()  # True 为缺失值

如果想要统计每列包含多少个缺失值，只需要添加 sum() 即可。

    df.isnull().sum()  # 统计每列缺失值数量

+ 删除数据

缺失值处理最简单的方法就是「不处理，直接删除」，你可能觉得这句话是个「玩笑」，其实真的存在。对于直接删除缺失数据，主要存在于以下几种情形：

    缺失数据占全部数据比例非常低，基本可以忽略不计，删除后且不会对整体数据分布产生影响。
    缺失数据因为本身特性无法填充，比如对于某些检测指标，如果填充不准确会严重影响最终结果。这种情况下，宁愿删除也不要进行处理。

Pandas 删除缺失数据的操作主要是通过 dropna() 完成。

    df.dropna() # 删除全部存在缺失值的行
    df.dropna(axis=1)  # 删除全部存在缺失值的列
    df.dropna(how='all')  # 删除全部值均为缺失值的行
    df.dropna(thresh=2)  # 删除行，且该行非缺失值少于 2 个

+ 填充缺失值

除了直接删除缺失值这种「简单又暴力」的操作，还有一种经常使用到的方法是对缺失值进行填充。而填充一般分为 3 种情况：

    固定值填充：人为指定，或使用行/列均值、中位数等。
    临近值填充：使用缺失值相临近的数值填充。
    数学填充：使用函数插值填充。

首先，我们学习如何使用固定值进行填充。这里可以直接使用 Pandas 提供的 replace 完成

    df.replace(np.nan, 0)  # 将缺失值填充为 0
    df.fillna(0)  # 将缺失值填充为 0
    df.fillna(df.mean())  # 使用各列平均值填充
    df.fillna(df.median())  # 使用各列中位数填充

当我们使用 fillna 填充缺失值时，我们还可以使用临近值填充。如果数据在短时间内的变化不大，那么临近值填充是一个很好的方式。例如气温数据的变化，如果已知 13:00 的气温而 13:15 数据缺失，那么就可以初略地使用 13:00 的气温填充 13:15 的缺失值。

同样，还是拿上面的 df 示例。

    df.fillna(method='bfill')  # 使用后一个临近数据向前填充
    df.fillna(method='ffill')  # 使用前一个临近数据向后填充

上面介绍了固定值和临近值填充方法。很多时候，数据虽然缺失但仍然能看出数据的变化趋势，此时更好的缺失值填充方法是使用数据方法进行插值。Pandas 中的 interpolate() 可以帮助我们快速应用一些常用的插值函数。
~~~
sample_data = {'A': [1, np.nan, 3, np.nan, 5, 6],
               'B': [1, 4, np.nan, np.nan, 25, 36]}

df = pd.DataFrame(sample_data)
~~~
你可以看到 A 列明显是线性增加趋势，而 B 列是 X2X^{2}X2 增加趋势。此时，如果用临近值填充显然不妥，就可以通过线性插值或者多项式插值完成。
~~~
df.interpolate(method='linear')  # 线性插值
df.interpolate(method='polynomial', order=2)  # 2 次函数插值
~~~

+ 重复值处理
使用 Pandas 提供的 duplicated() 方法判断重复值，如果存在重复值则返回 True。 drop_duplicates() 去除全部重复值。
drop_duplicates() 在去除重复值时，会对全部列进行判断。如果你只想去除 name 列的重复值，可以单独指定。
drop_duplicates() 默认保留重复项前面的值，而去除后面的值。你可以选择保留重复值最后出现的值。
~~~
df.duplicated()  # 判断重复值
df.duplicated().sum()  # 统计判断重复值
df.drop_duplicates()  # 去除重复值
df.drop_duplicates(['name'])  # 去除 name 列重复值
df.drop_duplicates(keep='last')  # 保留重复值最后一个
~~~

+ 异常值处理

除了缺失值与重复值，在处理数值型数据时，我们还容易遇到一种状况，那就是异常值。 异常值检测 是处理数值型数据过程中必须重视的一项工作。那些在收集、录入过程中产生的异常数据，如果不及时剔除，很可能对后续的预测分析带来严重不良影响。

应用数学和统计学领域对异常值检测研究比较深入，目前存在的检测方法也非常多。大致来讲，有从概率方法入手的一元正态分布及多元高斯方法，还有通过矩阵分解和神经网络进行异常值检测的相关方法。

在这里，我们介绍一种简单直观的异常值检测方法，那就是通过箱形图（箱线图）来识别异常数据。箱形图（下方红色）是用来观测数据集分布的一种图形类型。箱形图中，从下到上（下图从左到右）依次有 6 个数据节点，分别是：下界、下四分位、均值、中位数、上四分位、上界。

每一部分包含 1/4 的数据，这种划分的分割点就是四分位数。其中第 1 部分和第 2 部分的分割点称为第 1 分位数 Q1Q_1Q1​, 也被称为第 25 百分位数（下四分位）。第 3 部分和第 4 部分的分割点称为第 3 四分位数 Q3Q_3Q3​，也被称为第 75 百分位数（上四分位）。而第二部分和第三部分的分割点是第 2 四分数，也就是中位数。其中四分位距 IQRIQRIQR 是指第三四分位数和第一分四分位数的差，也就是 IQR=Q3−Q1IQR = Q_3 - Q_1 IQR=Q3​−Q1​。

所有小于 Q1−1.5IQR Q_1 - 1.5IQR Q1​−1.5IQR 或 大于 Q3+1.5IQR Q_3 + 1.5IQR Q3​+1.5IQR 的数据项被称为异常值。那么，我们就可以通过该判断依据来标记异常数据。



# 机器学习

##  感知机

感知机的结构非常简单，我们这里通过对它的几何介绍来认识感知机。感知机及像我们上面提到的车和房的分类例子，通过 w*x+b=0*w*∗*x*+*b*=0 这样一条直线将二维空间划分为两个区域，落在这两个区域中的点被归为正类和负类。

感知机的结构非常简单，我们这里通过对它的几何介绍来认识感知机。感知机及像我们上面提到的车和房的分类例子，通过 w*x+b=0*w*∗*x*+*b*=0 这样一条直线将二维空间划分为两个区域，落在这两个区域中的点被归为正类和负类。

![img](https://doc.shiyanlou.com/document-uid214893labid3466timestamp1504848794064.png)

有人可能会疑惑，如上图所示，划分两个区域的直线可能有多条，那么感知机会选取哪一条直线呢？

![img](https://doc.shiyanlou.com/document-uid214893labid3466timestamp1504848951479.png)

这就要谈到学习算法的学习策略了。感知机的学习策略是通过极小化下面的损失函数来选取最终的直线：

\min \sum y(w \cdot x+b)min∑*y*(*w*⋅*x*+*b*)

该损失函数表达的含义是误分类点到分离平面的总距离和。也就是说，误分类点越少越好，误分类点里分离平面的总距离和越小越好。

下面，我们动手实现感知机分类模型。我们先导入一个示例数据集，然后画出该数据集的图像。

```python
from matplotlib import pyplot as plt
import pandas as pd
%matplotlib inline

# 读取数据
data = pd.read_csv("two_class_data.csv", header=0)

# 读取数据列
x = data['x']
y = data['y']
c = data['class']

# 绘制散点图，c 参数用于分类着色
plt.scatter(x, y, c=c)
```

我们可以看到，该数据集是一个拥有明显二分类特征的数据集。

接下来，使用 scikit-learn 提供的感知机方法来对上面的数据集进行分类效果测试。首先定义特征变量和目标变量，并对数据集进行切分，70% 为训练集，30% 为测试集。

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Perceptron

# 定义特征变量和目标变量
feature = data[['x', 'y']].values
target = data['class'].values

# 对数据集进行切分，70% 为训练集，30% 为测试集。
X_train, X_test, y_train, y_test = train_test_split(
    feature, target, test_size=0.3, random_state=50)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

```

接下来，使用训练数据训练模型，并得到测试集上的预测结果。

```python
# 构建模型
model = Perceptron(max_iter=1000, tol=1e-3)
# 训练模型
model.fit(X_train, y_train)
# 预测
results = model.predict(X_test)
results
```

我们将预测结果绘制到散点图中。

```python
plt.figure(figsize=(9, 8))
# 以默认样式绘制训练数据
plt.scatter(X_train[:, 0], X_train[:, 1], alpha=0.3)
# 以方块样式绘制测试数据
plt.scatter(X_test[:, 0], X_test[:, 1], marker=',', c=y_test)
# 将预测结果用标签样式标注在测试数据左上方
for i, txt in enumerate(results):
    plt.annotate(txt, (X_test[:, 0][i], X_test[:, 1][i]))

```

我们可以看到，测试集中有数据被错误分类。绿色的方框被标记为了 C1。

除了看图，当然可以直接导出我们的分类评估数据：

```python
model.score(X_test, y_test)
```

如上可以得到测试集上的预测准确度。当然，这里如此高的分类正确率，很大程度是因为我们给的示例数据是非常理想的二分类数据。因实战过程中的数据肯定没有示例数据呈现出的线性可分性，你可以拿示例数据中的 `two_class_data_normal.csv` 数据文件自己试一下。

## 支持向量机

支持向量机是一种非常常用，适用性非常广的分类方法。与感知机不同的是，支持向量机不仅可以用于线性分类，还可以用于非线性分类。

支持向量机由 Vapnik 于 1963 年提出，与感知机不同的地方在于，支持向量机引入了「最大间隔」的思想来划定分割平面。这里所说的「最大间隔」如下图所示。

![img](https://doc.shiyanlou.com/courses/uid214893-20190617-1560765066589)

对于上图所示的蓝点和绿点两个类别而言，我们通过寻找距离两种类别间隔最大的平面 w*x-b=0*w*∗*x*−*b*=0 来作为分割平面。其中，实线与两条虚线的距离相等，且最大。

落在两条虚线上的白点或黑点被我们称之为「支持向量」，这也就是支持向量机的名字来源。

现在，我们通过支持向量机来重新对刚刚的 `two_class_data.csv` 进行重新分类。你只需要更改两行代码，分别是导入支持向量机 SVC 和使用 SVC 构建模型。

```python
from sklearn.svm import SVC

# 构建模型
model = SVC(gamma='scale')
# 训练模型
model.fit(X_train, y_train)
# 预测
results = model.predict(X_test)
results

plt.figure(figsize=(9, 8))
# 以默认样式绘制训练数据
plt.scatter(X_train[:, 0], X_train[:, 1], alpha=0.3)
# 以方块样式绘制测试数据
plt.scatter(X_test[:, 0], X_test[:, 1], marker=',', c=y_test)
# 将预测结果用标签样式标注在测试数据左上方
for i, txt in enumerate(results):
    plt.annotate(txt, (X_test[:, 0][i], X_test[:, 1][i]))

model.score(X_test, y_test)
```

对于该数据集而言，支持向量机的准确度应该会优于感知机。

除了线性分类，支持向量机还通过引入核函数来解决非线性分类的问题。我们依旧从几何角度来解释：

![img](https://doc.shiyanlou.com/courses/uid214893-20190617-1560763966008)

上面这三张图片演示了支持向量机解决非线性分类的过程。第一张中，红色小球和蓝色小球无法使用一条直线完成分类，于是我们通过核技巧将其映射到三维空间中（第二张），然后通过绿色的平面完成分类。最终再投影到二维空间中，平面投影下来就变成了一条曲线。

在将特征映射到高维空间的过程中，我们常常会用到多种核函数，包括：线性核函数、多项式核函数、高斯径向基核函数等。其中，最常用的就算是高斯径向基核函数了，也简称为 RBF 核。

下面，我们通过支持向量机完成一个非线性分类的任务。这里的示例数据 `zoo.csv` 来源于 UCI 数据网站。

`zoo.csv` 叫动物园数据集，总共有 18 列，第一列为动物名称，最后一列为动物分类。

![image](https://doc.shiyanlou.com/document-uid214893labid3466timestamp1504855848344.png)

数据集中间的 16 列为动物的特征，比如：是否有毛发、是否下蛋等。除了腿的数量为数值型，其余特征列均为布尔型数据。数据集中的动物共有 7 类，通过最后一列的数字表示。

接下来，我们尝试通过支持向量机完成这一个非线性的多分类任务。第一步依旧是导入 CSV 数据文件。然后定义其中 16 列为特征，最后一列为目标值。

```python
# 导入数据
data = pd.read_csv('zoo.csv', header=0)
# 定义特征变量和目标变量
feature = data.iloc[:, 1:17].values
target = data['type'].values
# 对数据集进行切分，70% 为训练集，30% 为测试集。
X_train, X_test, y_train, y_test = train_test_split(
    feature, target, test_size=0.3, random_state=50)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

# 构建模型
model = SVC(gamma='scale')
# 训练模型
model.fit(X_train, y_train)
# 预测
results = model.predict(X_test)
results

model.score(X_test, y_test)
```

不出意外的话，这里测试集的正确分类率为 0.867。我们有 16 个特征参与运算，但是得出的正确率并不高。其中一个主要原因是数据集太小了，总共才 100 行。





# 育种项目

## 碱基对在染色体上的分布

+ 用python计数

![image-20220314110503935](E:\Document\Typora\img\image-20220314110503935.png)

## 基因在染色体上的分布

![image-20220321103527383](E:\Document\Typora\img\image-20220321103527383.png)

![image-20220321095420365](E:\Document\Typora\img\image-20220321095420365.png)

## 20K碱基对在基因上的数据分布

| 染色体 | 碱基数量 | 基因上的碱基数量 | 基因数量 | 有碱基的基因数 |
| :----: | :------: | :--------------: | :------: | :------------: |
|   1    |   800    |       636        |   2457   |      626       |
|   2    |   983    |       849        |   3123   |      843       |
|   3    |   951    |       836        |   2649   |      825       |
|   4    |   917    |       763        |   2574   |      751       |
|   5    |   729    |       597        |   2491   |      591       |
|   6    |   990    |       882        |   3258   |      880       |
|   7    |   860    |       751        |   2743   |      735       |
|   8    |   967    |       853        |   3679   |      851       |
|   9    |   998    |       906        |   2865   |      903       |
|   10   |   920    |       787        |   2989   |      784       |
|   11   |   636    |       545        |   2570   |      544       |
|   12   |   660    |       540        |   2425   |      533       |
|   13   |   1053   |       942        |   3730   |      935       |
|   14   |   783    |       626        |   2245   |      617       |
|   15   |   1061   |       960        |   2774   |      943       |
|   16   |   792    |       708        |   2223   |      696       |
|   17   |   831    |       754        |   2627   |      732       |
|   18   |   1128   |       1024       |   3023   |      1013      |
|   19   |   958    |       841        |   2642   |      832       |
|   20   |   830    |       680        |   2502   |      683       |

## 60K碱基对在基因上的数据分布

| 染色体 | 碱基数量 | 基因上的碱基数量 | 基因数量 | 有碱基的基因数 |
| :----: | :------: | :--------------: | :------: | :------------: |
|   1    |          |       636        |   2457   |      626       |
|   2    |          |       849        |   3123   |      843       |
|   3    |   951    |       836        |   2649   |      825       |
|   4    |   917    |       763        |   2574   |      751       |
|   5    |   729    |       597        |   2491   |      591       |
|   6    |   990    |       882        |   3258   |      880       |
|   7    |   860    |       751        |   2743   |      735       |
|   8    |   967    |       853        |   3679   |      851       |
|   9    |   998    |       906        |   2865   |      903       |
|   10   |   920    |       787        |   2989   |      784       |
|   11   |   636    |       545        |   2570   |      544       |
|   12   |   660    |       540        |   2425   |      533       |
|   13   |   1053   |       942        |   3730   |      935       |
|   14   |   783    |       626        |   2245   |      617       |
|   15   |   1061   |       960        |   2774   |      943       |
|   16   |   792    |       708        |   2223   |      696       |
|   17   |   831    |       754        |   2627   |      732       |
|   18   |   1128   |       1024       |   3023   |      1013      |
|   19   |   958    |       841        |   2642   |      832       |
|   20   |   830    |       680        |   2502   |      683       |

## 基因数据补全





# xcel的tips

1.”CTRL+SHIFT+↓“可以直接选中到你之前选中那个单元格所在行的最后一行;

2.”CTRL+SHIFT+←或者→“可以选中整个列;

3.”CTRL+SHIFT+↓“再加上”CTRL+SHIFT+←或者→“就可以整列整列地选中,反之亦然;

+ 用excel进行分类计数

在数据栏选择分类







# Python

## 二维数组

[#Python# 二维数组的定义、使用的几种方法_锌录的博客-CSDN博客_python定义一个二维数组](https://blog.csdn.net/qq_39729672/article/details/90266122)

+ 二维数组初始化

~~~
[[[]for i in range(3)]for i in range(4)]
~~~

创建为3*4的数组



# Pandas

## drop

+ 删除未知名的列

~~~
correlations.drop(columns='Unnamed: 0', inplace=True)
~~~

[Pandas: Drop函数（Dataframe删除指定行列）_我是二师兄的博客-CSDN博客_data.drop](https://blog.csdn.net/W_weiying/article/details/84626260)

~~~
IN [1]: data
Out[1]: 
   A  B   C   D
0  0  1   2   3
1  4  5   6   7
2  8  9  10  11
 
IN [2]: data.drop(index=0) #删除index=0的行
Out[2]:  
   A  B   C   D
1  4  5   6   7
2  8  9  10  11
 
IN [3]: data.drop(labels=0, axis=0) #删除 "行号为0" 的行
Out[3]:  
   A  B   C   D
1  4  5   6   7
2  8  9  10  11
~~~





## 取数据

+ 取三行三列

~~~
 print(df.iloc[0:3,0:3])
~~~



## to_csv

[pandas的to_csv()使用方法_暖心生的博客-CSDN博客_pandas to_csv](https://blog.csdn.net/toshibahuai/article/details/79034829)

