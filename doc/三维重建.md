# 入门学习

[一分钟详解三维重建学习路线 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/191200982)

[三维重建初探(整理的一些资料及论文分享) - 简书 (jianshu.com)](https://www.jianshu.com/p/f33b3d440f7d)

[三维重建 3D reconstruction 有哪些实用算法？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/29885222)

![image-20211013140358366](E:\Document\Typora\img\image-20211013140358366.png)

# SFM

structure from motion，通过一组图片恢复三维模型。

[Photo Tourism (washington.edu)](http://phototour.cs.washington.edu/)



# 物体重建

[基于深度信息的大豆冠层株型参数计算方法研究（67页）-原创力文档 (book118.com)](https://max.book118.com/html/2020/0818/5310014104002332.shtm)



# 依赖库的安装

+ pcl

[Windows + VS2017超详细点云库（PCL）配置 | GYSHGX868's Notes](http://gyshgx868.github.io/2018/03/06/PointCloud/pcl-install/)

+ OpenGL

[OpenGL环境的配置（GLUT安装教程）_Pzx的博客-CSDN博客_opengl下载安装教程](https://blog.csdn.net/weixin_41962350/article/details/109345558)

+ kinect

[pcl、kinect、opencv和vs搭建_生活就要while-do的博客-CSDN博客](https://blog.csdn.net/weixin_44063985/category_8925211.html)







# kinect

## 从kinect获取点云数据

+ 运行程序报错

~~~
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\point_traits.h : warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失
1>c:\program files\pcl 1.8.1\3rdparty\vtk\include\vtk-8.0\vtkbuffer.h(156): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\visualization\interactor_style.h : warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\visualization\pcl_visualizer.h(1584): warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(130): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(130): note: 此诊断出现在编译器生成的函数“void pcl::eigen22(const Matrix &,Matrix::Scalar &,Vector &)”中
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(169): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(169): note: 此诊断出现在编译器生成的函数“void pcl::eigen22(const Matrix &,Matrix &,Vector &)”中
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(226): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(226): note: 此诊断出现在编译器生成的函数“void pcl::computeCorrespondingEigenVector(const Matrix &,const Matrix::Scalar &,Vector &)”中
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(258): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(258): note: 此诊断出现在编译器生成的函数“void pcl::eigen33(const Matrix &,Matrix::Scalar &,Vector &)”中
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(292): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(292): note: 此诊断出现在编译器生成的函数“void pcl::eigen33(const Matrix &,Vector &)”中
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(309): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\common\impl\eigen.hpp(309): note: 此诊断出现在编译器生成的函数“void pcl::eigen33(const Matrix &,Matrix &,Vector &)”中
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\visualization\impl\pcl_visualizer.hpp(1429): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\visualization\impl\pcl_visualizer.hpp(1429): note: 此诊断出现在编译器生成的函数“bool pcl::visualization::PCLVisualizer::updatePointCloud(const pcl::PointCloud<PointT>::ConstPtr &,const std::string &)”中
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\visualization\impl\pcl_visualizer.hpp(1465): error C2589: “(”:“::”右边的非法标记
1>c:\program files\pcl 1.8.1\include\pcl-1.8\pcl\visualization\impl\pcl_visualizer.hpp(1465): note: 此诊断出现在编译器生成的函数“bool pcl::visualization::PCLVisualizer::updatePointCloud(const pcl::PointCloud<PointT>::ConstPtr &,const pcl::visualization::PointCloudGeometryHandler<PointT> &,const std::string &)”中
~~~

解决方法：[error C2589: “(”: “::”右边的非法标记_u010828750的博客-CSDN博客](https://blog.csdn.net/u010828750/article/details/82216884)

头文件之前写

~~~
#undef max
#undef min
~~~



### setCameraPosition

![image-20220114171218962](E:\Document\Typora\img\image-20220114171218962.png)

position 和 focal point定义了相机的位置和投影方向，Front Clipping Plane为CCD镜头平面（图像平面），Back Clipping Plane平面为物体平面。


[37 VTK中的坐标系系统 - 十步一杀2017 - 博客园 (cnblogs.com)](https://www.cnblogs.com/ghjnwk/p/10305796.html)





# pcl

![image-20220112155633185](E:\Document\Typora\img\image-20220112155633185.png)

![image-20220112155654339](E:\Document\Typora\img\image-20220112155654339.png)

+ 超级棒的入门教程

[PCL(Point Cloud Library)学习指南&资料推荐 · 语雀 (yuque.com)](https://www.yuque.com/huangzhongqing/pcl/rdk5k8)

[01-点云及其可视化 - 黑马机器人 | PCL-3D点云 (czxy.com)](https://robot.czxy.com/docs/pcl/chapter01/intro/)



# Three.js

## 学习路径

1.**学习前端最基本的语言**：没什么说的，html、cs、js的基础得学啊，最早入门学的head first系列，建立基本概念后，圣经《[javascript 高级](https://www.zhihu.com/search?q=javascript+高级&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A832014537})程序设计》；

2.在上一步的开展同时，其实就可以建立一些图形学的基本概念，买一个计算机图形学相关的书，从头到尾看一遍（很多内容看不懂没关系，能看懂多少算多少，有个概念即可）；

3.opengl可以先不学，直接过一本书：《[WebGL编程指南](https://www.zhihu.com/search?q=WebGL编程指南&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A832014537})》，很基础的书，在1的基础上，按照书中案例走一遍。

4.两个选择，threejs官网走一遍案例，或者《[three.js开发指南](https://www.zhihu.com/search?q=three.js开发指南&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A832014537})》，当然两者同时更好啦。[Three.js教程 (webgl3d.cn)](http://www.webgl3d.cn/Three.js/)



# NERF

[CVPR 2021｜pixelNeRF：一种基于NeRF的多视图三维重建网络 (baidu.com)](https://baijiahao.baidu.com/s?id=1698982827739127187&wfr=spider&for=pc)

[NeRF算法_billbliss的专栏-CSDN博客_nerf算法](https://blog.csdn.net/billbliss/article/details/120457122)

[图形学新高潮? NeRF 笔记 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/187541908?utm_source=wechat_session)

[惊艳的NeRF算法，可用于视图合成的神经辐射场技术-技术圈 (proginn.com)](https://jishuin.proginn.com/p/763bfbd62dad)

[VR丝滑全景指日可待？谷歌这个360° NeRF让人看到未来 (baidu.com)](https://mbd.baidu.com/newspage/data/landingsuper?context={"nid"%3A"news_9696235171474586526"}&n_type=1&p_from=4)

[NeRF: Neural Radiance Fields (matthewtancik.com)](https://www.matthewtancik.com/nerf)

图形学主要研究的是3D模型到2D投影平面映射. 3D模型可以有多种表示方法, 到目前为止, 有诸如mesh, point-cloud, voxel, depth map, multi-plane image, SDF等等. 它们都各自的优缺点. 今天分享的是一种新的3D模型表达方式. 简而言之就是用神经网络来拟合一个类似voxel的模型.

## 核心思路

体模型由3D grid中的每个格点(体素voxel)构成, 每个体素有颜色(RGB值)+透明度(α值)属性, NeRF的想法就是用一个全连接神经网络来拟合出一个连续的体素表示. 这个全连接网络输入想要的位置(x, y, z), 以及看的角度(φ, ψ), 输出该位置的颜色(r, g, b)和该点的透明度/density(α). 在理想状态下, 要是这个神经网络能和真实场景有一样的输入和输出, 我们就能用这个神经网络来表示这个模型了.

为什么要输入看的角度呢, 因为其实这个网络不光想拟合这个体模型, 它还想要拟合这个场景的光照. 因为在有光照的条件下, 颜色输出是和看的视角有关的(参见BRDF). 所以才会加入角度.

## 细节

1. 首先模型输出的α应该和看的角度没关系(因为光照不会影响透明度, 只是透明度会影响颜色), 但是rgb却和看的角度有关系, 所以在模型中也force了这个条件, 将看的角度作为中间量输入(详见我画的图)
2. 其次是position embedding. 在实验中发现假如只是输入position(3d), 输出会很模糊(over smooth), 因为好像神经网络只能学到低频的东西. 所以NeRF把输入做了embedding. 就是将3d的输入映射到一个高维的空间去. 和NLP里常用的embedding差不多. 我的理解是类似于将一维的空间映射到了频域空间, 所以下面的L越大, 能表达的细节就越多(我是这么感觉的, 不知道对不对).

![image-20220311144230779](E:\Document\Typora\img\image-20220311144230779.png)

## 基于辐射场的体素渲染算法

体素的渲染就是沿着光线的方向积分得到最终的颜色值. 但是计算机不能积分, 只能用离散的方法逼近. 要想达到比较好的积分效果一般用重要性采样(用概率来理解积分, 用求期望的方法来算积分)(其实图形学为了达到又快又好的积分效果, 提出了很多奇技淫巧). 作者的话先用粗略的uniform采样, 得到被积函数的大致曲线, 然后在更精细的基于刚刚得出的大致曲线进行重要性采样. 这样最终得出rgb的值.

![image-20220311144447690](E:\Document\Typora\img\image-20220311144447690.png)



NeRF 函数得到的是一个3D空间点的颜色和密度信息，但当用一个相机去对这个场景成像时，所得到的2D 图像上的一个像素实际上对应了一条从相机出发的射线上的所有连续空间点。我们需要通过渲染算法从这条射线上的所有点得到这条射线的最终渲染颜色。同时，为了保证网络可以训练，NeRF中需要采用可微的渲染方法。

*1. 经典的volume rendering 方式*

![image-20220311150714859](E:\Document\Typora\img\image-20220311150714859.png)

但是，实际应用中，我们并不可能够用NeRF去估计连续的3D点的信息，因此就需要数值近似的方法。这里也是NeRF中非常核心的一个部分。

*2. 基于分段随机采样的离散近似volume rendering方式*

![image-20220311150727634](E:\Document\Typora\img\image-20220311150727634.png)

一个直观且很常用的思路是，在需要求积的区域均匀地采样N个点进行近似计算。但作者提出，这样的方式会导致MLP只需要学习一系列离散点的信息，最终会限制NeRF的分辨率，使得最终生成的结果不够清晰。作为替代，作者提出了一种简单有效的方法，如上图所示，首先将射线需要积分的区域分为N份，然后在每一个小区域中进行均匀随机采样。这样的方式能够在只采样离散点的前提下，保证采样位置的连续性。第i个采样点可以表示为：

![image-20220311150751563](E:\Document\Typora\img\image-20220311150751563.png)

同样，基于分段采样的渲染方式也是可微的。因此，基于这样的渲染方式，我们就可以用NeRF函数从任意角度中渲染出图片。



## 训练

1. training就比较直观了, 因为可以从网络渲染出任意视角的图片, Loss就是简单的渲染图片和真实图片的MSE loss.
2. 因为说回来这个work的任务还是novel view synthesis, 所以training data就是各个视角下拍的图片, 以及因为你得给定相机的位姿才能得到渲染的图片, 所以还得知道training data各张图片的内外参.



## 公式

NeRF【1】将场景编码为颜色和密度的连续体积辐射场f。特别地，对于一个3D点x和

观察方向单位向量d，f返回微分密度σ和RGB颜色c：f(x, d) = (σ, c)。体积辐射场可以通过下面的函数渲染成2D图像：

![image-20220311143351727](E:\Document\Typora\img\image-20220311143351727.png)

其中T(t)处理遮挡。对于具有姿态P的目标视图，相机光线可以参数化为r(t)=o+td，o为光线原点(相机中心)。沿着相机光线在预定义的深度边界[tn，tf]之间计算积分。在实践中，这种积分是通过沿每个像素射线采样点的数值求积来近似的。

然后，将摄影机光线r的渲染像素值与对应的真实像素值C(r)进行比较，最后的loss定义如下：

![image-20220311143540987](E:\Document\Typora\img\image-20220311143540987.png)
