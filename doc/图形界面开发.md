# 触摸屏

[WPF 触摸屏应用需要了解的知识_lindexi_gd的博客-CSDN博客_wpf 触摸屏](https://blog.csdn.net/lindexi_gd/article/details/106764496?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.pc_relevant_antiscanv2&spm=1001.2101.3001.4242.1&utm_relevant_index=3)

## 触摸屏等于触摸框加屏幕
触摸屏必须要分开看，至少在软件上需要将触摸屏分开为触摸框加屏幕两个模块，因为触摸框会直接影响软件的形态以及逻辑。而屏幕虽然也会影响，但是已经有大量驱动和底层的渲染库解决这部分问题，理论上除非写很底层的开发，否则需要关心的只是屏幕分辨率以及频率，而不需要关心屏幕的显示效果

触摸框提供了触摸输出，而屏幕接收软件的输出。因此一个触摸屏应用拆分为触摸框和屏幕就能拆分两个模块，分别是软件的输入和输出对应的模块

接下来需要告诉大家触摸框有哪些了

触摸框大概可以分为电磁屏、电容屏和红外屏，以及其他屏。我经手最多的是电磁屏、电容屏和红外屏。不同的屏幕对软件的实现逻辑有一定的影响

## 红外屏
红外屏幕，即红外触摸框，属于成本最低的一个触摸框。基本上市面上的红外触摸框都属于低成本方案。但红外也依然能做到高精度低延时，不过高端红外触摸屏的成本会比同等的电容屏贵一些。当然，这不是绝对的，取决于销售大佬的能力

红外屏的开发需要了解到的是红外是不区分触摸物体的，这个和电磁屏、电容屏相对。红外触摸框的原理是通过光线判断，只要有物体接触屏幕，挡住了光线，就会被触摸框识别到触摸

敲黑板，如果开发的应用会在红外屏上面运行，那么请务必记住上面这句话

注意，任何物体只要挡住了红外触摸框发射的光线，那么将会被识别为触摸

而红外触摸框是通过在屏幕之上添加一个触摸框，因此你可以不必贴合屏幕进行触摸即可被识别为触摸。这个被称为触摸高度。触摸高度指的是距离碰到屏幕的距离有多少就会挡住红外的光线，被识别为触摸

有了触摸高度以及任意物体只要挡住光线即可被识别为触摸，将会给开发带来一些坑

在红外屏开发的时候需要注意屏幕本身是不平的，因此一个屏幕的不同的点的触摸高度可能不同。而如果使用笔之类的三角形大概的物体触摸的时候，此时因为触摸高度不同，因此识别到的触摸面积以及坐标可能不同

因此在红外屏开发的时候，需要注意触摸点需要做很多的补偿，需要做至少一次贝赛尔。如果遇到离群点，需要干掉

默认在 Windows 底层已经做过一次处理了，但是针对于比较便宜的红外触摸框加屏幕做工，需要手动处理离群点的丢掉问题。记住一个参数，在10ms内移动距离不超过xx像素。注意这个 xx 像素是因为软件里面只能知道像素，而不知道物理距离尺寸。因此需要根据具体触摸框和屏幕测试出这个像素值。如果移动距离超出了，请丢这个点

而红外屏会带来的另一个问题是大面积物体触摸问题，假定有一个海绵准备触摸红外屏。在第一刻，你能收到超级多的点离散触摸到屏幕，此时属于多指触摸。而在第二刻你能收到一个比较混乱的值，有一些点的触摸面积变大，而一些点消失或不动，这取决于触摸框供应商的算法。在第三刻就剩下几个点了，同时几个点是存在重叠的

因此在红外屏处理大面积物体触摸的时候，需要做延迟，延迟判断触摸面积到达多大。例如手势擦除功能，不能拿到第一个点获取面积就判断是进行手势擦除或不是手势擦除。注意这里说的手势擦除是一个团队内的术语，听不懂，没关系

而同时需要注意有处理多指触摸的业务的时候，不能在多指触摸立刻响应，需要做延迟，延迟一定的时间如果依然是多指触摸才能进行业务，或者需要设计多指触摸业务可以被打断

因此遇到以下问题的时候，需要想到这是红外屏的特性

触摸出现瞬间跳点
触摸的时候两个手指距离过近出现黏线，不同角度的黏线距离不同
获取到物体的触摸面积在不同的坐标获取到的值不同
相同触摸点移动过程中面积变化
相同触摸点移动过程中，中心点变化
可能存在某个点一直都是被触摸，但找不到这个点的触摸物体
触摸移动过快的时候被识别为两段触摸，或者两个不同的手指触摸
红外屏还能有一些好玩的坑，这部分我记录到本文最后的笑话的这一节

## 电容屏
电容屏会遇到的问题是触摸的时候不一定会响应，同时要求物体几乎完全贴合屏幕才能收到触摸点。为什么触摸的时候不一定会响应，一个原因是触摸的物体的缘故，需要能导电，另外的原因和屏幕的做工相关

电容屏识别物体的面积都是比较准的，但是如果有一个大面积物体触摸的时候，这个物体触摸面不是平整的，意味着可能有部分点能触摸到。而一部分触摸不到，如手背。此时收到的触摸可能是一些离散的点，而不是一个大物体

因此在电容屏上的应用，如果考虑大面积触摸，需要软件添加对相邻触摸点连在一起作为一个新的触摸点的功能

而这部分软件的功能不一定放在应用软件，有一些供应商的触摸框做了这个处理。如果触摸框厂商提供的比较渣，就需要应用软件加上这个逻辑

电容屏的问题是触摸的时候需要差不多完全贴合，而因为屏幕的材料存在摩擦，因此手指滑动的时候会出现瞬间的抬起，因此可能存在瞬间的触摸抬起然后继续触摸

需要软件兼容如果收到抬起之后的 xx ms 再次在抬起的点附近收到按下的点，那么将两个点连接起来。这里的参数需要根据实际的触摸框修改

## 电磁屏
基本上对应的是电磁笔，这个屏幕因为有电磁笔的存在，因此触摸的坑少了，而笔的坑就多了一些

基本上笔是存在压感的，而默认微软能提供的笔有限。因此做多笔可以尝试使用压感的值分开多个不同的笔。如果你这样做了，后续的坑，相信你也能预料到

而一般的电磁屏和上面两个没有冲突，可以使用电磁屏配合红外屏做到手笔分离的功能。使用电磁笔是写字上报的是Pen协议消息，而使用手触摸走的是红外，上报的是触摸信息

在 WPF 中区别在于笔写字的时候触发的是触笔 Stylus 事件，而触摸的时候则是触发 Touch 以及 Stylus 事件

## 触摸面积和物理面积
其中触摸面积是一个大坑，尽管标准 HID 协议里面的触摸包含了 X Y 和 宽度高度，但是坑的在于宽度和高度是没有单位的。没有单位意味着每个厂商都可以按照自己的期望随意给任意的值

因此有不同的触摸框厂商导入的时候就需要做好这部分的兼容，这部分仅仅是项目管理上的事情以及协议上的事情，和技术无关。但是做不好将会很坑

而触摸报告上来的宽度和高度其实有两个含义，一个含义是物理值，另一个含义是逻辑值。这两个值是什么意思？物理值就是触摸框物理收到了多大的面积，就报告多大。而逻辑值是根据当前屏幕的分辨率和尺寸等给定一个逻辑上计算出来的值，逻辑值主要是让不同的触摸框上报给应用一个大概相同的值

而应用显示触摸面积的大小也是一个神坑，原因是上面说的屏幕分辨率可不是系统分辨率。同时屏幕的大小和分辨率没有本质的联系。一个 10 寸的屏幕可以是 2k 分辨率，而一个 100 寸的屏幕可以是 1k 分辨率。而分辨率和像素相关，应用程序能控制的仅仅是像素。因此就需要应用程序知道当前运行过程中像素和物理尺寸的换算比例是多少，这部分需要应用程序和硬件配合，应用程序询问硬件当前的型号以及显示屏幕的尺寸。同时知道当前系统的分辨率，以此进行缩放，拿到当前像素和物理尺寸转换的参数。然后和触摸框部分协议报告上来的面积的含义，以此转换为实际渲染像素

需要注意的是 WPF 默认是像素无关的，这部分想要达到更好的控制，还需要了解 DPI 和分辨率的关系等细节。这部分请看下面博客

[支持 Windows 10 最新 PerMonitorV2 特性的 WPF 多屏高 DPI 应用开发 - walterlv](https://blog.walterlv.com/post/windows-high-dpi-development-for-wpf.html)

[Windows 下的高 DPI 应用开发（UWP / WPF / Windows Forms / Win32） - walterlv](https://blog.walterlv.com/post/windows-high-dpi-development.html)

[Windows DPI Awareness for WPF - walterlv](https://blog.walterlv.com/windows/2014/09/20/windows-dpi-awareness-for-wpf.html)

##  协议文档
现在 HID 设备是有一套国际标准的协议，触摸和触笔也都有对应的协议。按照协议来可以减少很多坑，同时也能很好做到适配

详细请看[Windows 的 Pen 协议 (lindexi.com)](https://blog.lindexi.com/post/Windows-的-Pen-协议.html)

而国际标准仅仅能做到的是很少的功能，有很多强大的功能还是需要触摸框配合作出私有协议，通过私有协议实现软硬件协同。在 WPF 中可以直接读取 HID 设备的方法读取触摸框的私有协议。但是触摸框 HID 默认会被系统独占，因此私有协议需要另开一路 USB 等设备才能做到

如果是多个触摸框屏幕想要在同一个应用上玩，默认的 Windows 是不支持的，此时需要用到读取裸数据的方法，请看 [WPF 使用 RawInput 接收裸数据 (lindexi.com)](https://blog.lindexi.com/post/WPF-使用-RawInput-接收裸数据.html)

# 专有名称

## DPI

DPI（Dots Per Inch，每英寸点数）是一个量度单位，用于点阵[数码影像](https://baike.baidu.com/item/数码影像/6208065)，指每一[英寸](https://baike.baidu.com/item/英寸)长度中，取样、可显示或输出点的数目。

DPI 值有两种：系统 DPI (System DPI) 和屏幕 DPI (Monitor DPI)。自 Windows Vista 开始引入系统 DPI 概念，自 Windows 8.1 开始引入屏幕 DPI 概念。

![Windows 7 的 DPI 设置](https://blog.walterlv.com/static/posts/2021-01-04-20-25-29.png)



**描述分辨率的单位：**
**DPI：**dots per inch，表示每英寸（对角线长度）能打印上的墨滴数量。最初应用于打印技术中。打印设备多在 300 至 3600 DPI 之间。
**PPI：**[pixels per inch](https://www.zhihu.com/search?q=pixels+per+inch&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1133513546})，电子显示设备从打印设备中借鉴了 DPI 的概念，产生了 PPI的概念。即显示器每英寸（对角线长度）上像素点的数量，指[像素密度](https://www.zhihu.com/search?q=像素密度&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1133513546})。



# 图形界面开发平台

## 跨平台

### QT



[QT：触摸屏支持手指触摸，增加touch事件touchevent，记录前后touch坐标并处理_比特的一天的博客-CSDN博客_qt touchevent](https://blog.csdn.net/qq_43473694/article/details/110404963)





## windows

[UWP 和 WPF 对比 - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1341989)

### windows Forms

+ 2002年推出
+ windows 7 SP1及以上系统
+ 在 .NET Framework 4.7 才开始支持屏幕级 DPI 感知的。不过部分控件不支持自动随屏幕 DPI 切换。



### WPF

[在 Visual Studio 2019-.NET Framework 中创建第一个 WPF 应用 | Microsoft Docs](https://docs.microsoft.com/zh-cn/dotnet/desktop/wpf/getting-started/walkthrough-my-first-wpf-desktop-application?view=netframeworkdesktop-4.8)

[演练：创建你的第一个触控应用程序 - WPF .NET Framework | Microsoft Docs](https://docs.microsoft.com/zh-cn/dotnet/desktop/wpf/advanced/walkthrough-creating-your-first-touch-application?view=netframeworkdesktop-4.8)

+ 时间：2006年推出
+ 系统版本：windows 7 SP1及以上系统

+ 触摸屏支持：支持触摸屏，但是效果不太好
+ DPI：支持最新的 DPI 感知级别，不过依然有限制
+ 渲染引擎：使用托管代码计算，然后通过通道使用 DirectX 9 渲染

+ 开发语言：XAML+C#



### UWP

+ 时间：2015/2012年推出
+ 系统版本：只支持windows 10
+ 触摸屏支持：支持触摸屏
+ DPI：支持最新的各种 DPI 感知级别，而且是完全支持
+ 使用DirectComposition直接渲染，使用 DX11 渲染

+ 开发语言

~~~
XAML UI 和 C#、VB 或 C++
DirectX UI 和 C++
JavaScript 和 HTML
WinUI
~~~

[什么是通用 Windows 平台 (UWP) 应用？ - UWP applications | Microsoft Docs](https://docs.microsoft.com/zh-cn/windows/uwp/get-started/universal-application-platform-guide)

[C# winform用sharpGL（OpenGl）解析读取3D模型obj_HOLD ON!的博客-CSDN博客_c#读取obj](https://blog.csdn.net/cxu123321/article/details/103703591)

### winUI 3

[C++/WinUI 3 技术笔记（一） - lyincc - 博客园 (cnblogs.com)](https://www.cnblogs.com/lyincc/p/cpp-winui-3-note-01.html)

[春风十里不如你，全新Windows UI 3(WinUI 3) 的第一个实现Project Reunion 0.5 - TaylorShi - 博客园 (cnblogs.com)](https://www.cnblogs.com/taylorshi/p/14673459.html)

## linux

[linux触摸屏（一）编写触摸屏应用_gaosiniquanjia的博客-CSDN博客_linux触摸](https://blog.csdn.net/gaosiniquanjia/article/details/113897586)

### GTK

+ GTK+ 3.3.18支持触摸屏设备



## 移动端

### 安卓

+ 时间：2007年
+ 渲染工具：OpenGL

+ 



#### 1) Location-Based Services（定位服务）

Android 操作系统支持 GPS API-LBS，可以通过集成 GPS 芯片来接收卫星信号，通过 GPS 全球定位系统中至少 3 颗卫星和原子钟来获取当前手机的坐标数据，通过转换就可以成为地图上的具体位置，这一误差在手机上可以缩小到 10 米。在谷歌开发手机联盟中可以看到著名的 SiRF star。所以未来 gPhone 手机上市时集成 GPS 后的价格不会很贵。

同时，谷歌正在研制基于基站式的定位技术——MyLocation，可以更快速地定位，与前者 GPS 定位需要花费大约 1 分钟相比，基站定位更快。

#### 2) Media APIs（多媒体接口）

Android 平台上集成了很多影音解码器以及相关的多媒体 API，通过这些可选 API，厂商可以让手机支持 MP3、MP4、高清晰视频播放处理等。

#### 3) 3D Graphics with OpenGL（3D 图形处理 OpenGL）

可选 API。Android 平台上的游戏娱乐功能，如支持 3D 游戏或应用场景就需要用到 3D 技术，手机生产厂商根据手机的屏幕以及定位集成不同等级的 3D 加速图形芯片来加强 gPhone 手机的娱乐性，有来自高通的消息称，最新的显示芯片在 gPhone 上将会轻松超过索尼 PS3。

#### 4) Low-Level Hardware Access（低级硬件访问）

这个功能主要用于控制手机的底层方面操作，设计底层硬件操作将主要由各个手机硬件生产厂商来定制，支持不同设备的操作管理，如蓝牙 (Bluetooth) 以及 WIFI 无线网络支持等。

关注微信公众号「站长严长生」，在手机上阅读所有教程，随时随地都能学习。本公众号由[C语言中文网站长](http://c.biancheng.net/view/8092.html)运营，每日更新，坚持原创，敢说真话，凡事有态度。



### 苹果



# Android

## 项目配置

![image-20220402171743517](E:\Document\Typora\img\image-20220402171743517.png)

### project视图

gradle和idea自动生成文件，打包可删

+ gradle 构建器

![image-20220402171834004](E:\Document\Typora\img\image-20220402171834004.png)

+ .gitignore  版本控制
+ build.gradle  项目全局的gradle构建脚本
+ gradle.properties  gradle的配置文件
+ gradlew     gradlew.bat  和操作系统有关，前者用于linux和mac系统，后者用于windows系统
+ local.properies   sdk的路径
+ settings.gradle   引入的模块

### 安卓视图

+ 配置文件

![image-20220406093749319](E:\Document\Typora\img\image-20220406093749319.png)

<intent-filter>表示意图识别器，指定当前为启动界面，第二句让页面在应用列表里面形成图标

+ 主函数

~~~
public class MainActivity extends AppCompatActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);	// 设置布局文件
    }
}
~~~

### gradle

Android主流的编译工具

setting.gradle  build.gradle  针对某个项目的配置

build.gradle应用所有项目的配置

+ minSdkVersion:最小API level
+ compileSdkVersion:编译的SDK版本
+ targetSdkVersion:目标版本
+ dependecies:依赖配置，依赖的

## 详解helloworld

Activity

​	-- MainActivity

Activity:可视化界面

​	-- onCreate()

进入界面时，触发改方法

​	-- setContentView()

设置视图内容

R:为每个资源文件按照类别分配一个索引，通过R.类别名.资源名操作对应资源

布局文件

清单文件

## 打印日志

~~~
Log.v("Tag","Msg");//Verbose  观察值，Verbose是冗长、啰嗦的意思，任何消息都会输出
Log.d("Tag","Msg");//Debug  调试
Log.i("Tag","Msg");//Info  信息，为一般提示性的消息
Log.w("Tag","Msg");//Warn  可能会出问题，一般用于系统提示开发者需要优化android代码等场景
Log.e("Tag","Msg");//Error  崩溃信息，一般用于输出异常和报错信息
~~~

比如`TAG = "PlaneActivity";`

![image-20220412111153284](E:\Document\Typora\img\image-20220412111153284.png)

对应的log如下

![image-20220412111226613](E:\Document\Typora\img\image-20220412111226613.png)

## 常用布局

+ 线性布局（LinearLayout）

![image-20220406111546553](E:\Document\Typora\img\image-20220406111546553.png)

![image-20220406112703448](E:\Document\Typora\img\image-20220406112703448.png)

`match_parent`符合窗口的大小匹配



+ 相对布局（RelativeLayout）
+ 帧布局（Frame Layout）
+ 表格布局（Table Layout）
+ 网格布局（GridLayout）
+ 约束布局（ConstraintLayout）

### 布局重要属性

![image-20220406112447197](E:\Document\Typora\img\image-20220406112447197.png)

### 线性布局

![image-20220406143530600](E:\Document\Typora\img\image-20220406143530600.png)

+ 方向

~~~
android:orientation="horizontal"  // vertical(垂直)
~~~

+ 背景色

~~~
android:background="#ff0000"
~~~



### 相对布局

![image-20220408152844401](E:\Document\Typora\img\image-20220408152844401.png)

### constrain布局

`app:layout_constraintLeft_toLeftOf="parent"`
从字面上看，指的是让该控件的左侧与父布局对齐，当我们希望控件A与控件B左侧对齐时，就可以使用该属性。

`app:layout_constraintLeft_toLeftOf="@id/viewB"`
类似的还有个相似的属性为：

`app:layout_constraintLeft_toRightOf`
很好理解，即当前属性的左侧在谁的右侧，当我们希望控件A在控件B的右侧时，可以设置：

`app:layout_constraintLeft_toRightOf="@id/viewB"`
与之类似的还有几个属性：

~~~
layout_constraintRight_toLeftOf
layout_constraintRight_toRightOf
layout_constraintTop_toTopOf
layout_constraintTop_toBottomOf
layout_constraintBottom_toTopOf
layout_constraintBottom_toBottomOf
layout_constraintBaseline_toBaselineOf
~~~

## menu菜单

[Android的Menu菜单，这一篇就够了 - 简书 (jianshu.com)](https://www.jianshu.com/p/3cd563a377ff)



逻辑，先`onCreateOptionsMenu`设置菜单栏

~~~
public boolean onCreateOptionsMenu(Menu menu) {
	getMenuInflater().inflate(R.menu.plane_menu_filter, menu);
	return super.onCreateOptionsMenu(menu);
}
~~~

打开菜单栏的时候运行`onMenuOpened`

~~~
public boolean onMenuOpened(int featureId, Menu menu) {
    glSurfaceView.onPause();
    Log.i(TAG, "onMenuOpened");
    return super.onMenuOpened(featureId, menu);
}
~~~

选择菜单栏之后运行`onOptionsItemSelected`，获取selectId







## 布局及控件组成

![image-20220408170256251](E:\Document\Typora\img\image-20220408170256251.png)







## OpenGL ES渲染

[android平台下OpenGL ES 3.0从零开始 - 简书 (jianshu.com)](https://www.jianshu.com/p/79511ef8ac95)

[七 OpenGL ES 2.0 渲染流程整理_丿寒风的博客-CSDN博客](https://blog.csdn.net/xufeng0991/article/details/51958492)

![image-20220406161259485](E:\Document\Typora\img\image-20220406161259485.png)

+ 顶点着色器 Vertex Shader

针对顶点执行一次，用于确定顶点的位置（位置、颜色、[纹理](https://so.csdn.net/so/search?q=纹理&spm=1001.2101.3001.7020)坐标）

+ 片元着色器 Fragment Shader

计算每个像素的颜色及属性。可通过应用光照值、贴图、阴影、镜面光、透明度等信息计算像素颜色值并输出。

[OpenGL的基础光照和计算_csxiaoshui的博客-CSDN博客](https://blog.csdn.net/csxiaoshui/article/details/53332647)

### 环境构建

#### 理解obj文件

“#”号开头的行为注释，描述模型的一些基本信息，在程序加载的过程中可以忽略。

这个部分会写mtl文件的文件名

关于mtl文件

mtl文件是**3D Studio软件默认存储文件的扩展名**。 mtl文件（Material Library File）是材质库文件，描述的是物体的材质信息， 用3Dmax导入即可。

“v”开头的行用于存放顶点坐标，其后面的3个数值分别表示一个顶点的X、Y、Z坐标。

“vn”开头的行用于存放顶点法向量，其后面的3个数值分别表示一个顶点的法向量在X轴、Y轴、Z轴上的分量。

“vt”开头的行用于存放顶点纹理坐标，其后面的3个数值分别表示纹理坐标的S、T、W分量（S、T为纹理采样坐标，W指的是深度纹理坐标，主要用于3D纹理的采样，OpenGL ES 2.0中对3D纹理还没有普遍支持，故这里不使用）

“f”开头的行表示一个面，如果是三角形，（由于OpenGL ES仅支持三角形，故我选择的obj模型都是基于三角形面的）则后面有3组用空格分隔的数据，代表三角形的3个顶点，每组数据包含3个数值，用“/”分隔，依次表示顶点坐标数据索引，顶点纹理坐标数据索引，顶点法向量数据索引。例如有这样一行“ f 238/240/239 243/245/244 244/247/245 ”，则表示这个三角形面中3个顶点的坐标分别来自第238、243、244号“v”开头的行，3个顶点的纹理坐标分别了来自第240、245、247号“vt”开头的行，3个顶点的法向量分别来自第239、244、245号“vn”开头的行。

#### 在清单中声明 OpenGL ES 的使用

为了让您的应用使用 OpenGL ES 2.0 API，您必须将以下声明添加到清单中：

```xml
    <uses-feature android:glEsVersion="0x00020000" android:required="true" />
```

如果您的应用使用了纹理压缩，您还必须声明应用支持哪些压缩格式，以便应用仅在兼容的设备上安装。

```xml
    <supports-gl-texture android:name="GL_OES_compressed_ETC1_RGB8_texture" />
    <supports-gl-texture android:name="GL_OES_compressed_paletted_texture" />
```

如需详细了解纹理压缩格式，请参阅 [OpenGL](https://developer.android.google.cn/guide/topics/graphics/opengl?hl=zh-cn#textures) 开发者指南。

添加位置：

[Android Studio中的AndroidManifest.xml文件分析 - 虚生 - 博客园 (cnblogs.com)](https://www.cnblogs.com/dylancao/p/12043646.html)

#### 为 OpenGL ES 图形创建 Activity

使用 OpenGL ES 的 Android 应用的 Activity 与其他任何具有界面的应用相同。这种应用与其他应用的主要区别在于您在 Activity 的布局中添加了哪些内容。在很多应用中，您可以使用 `TextView`、`Button` 和 `ListView`；而在使用 OpenGL ES 的应用中，您还可以添加一个 `GLSurfaceView`。

以下代码示例展示了使用 `GLSurfaceView` 作为主要视图的 Activity 的最低实现：

~~~
public class OpenGLES20Activity extends Activity {

    private GLSurfaceView gLView;

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);

        // Create a GLSurfaceView instance and set it
        // as the ContentView for this Activity.
        gLView = new MyGLSurfaceView(this);
        setContentView(gLView);
	}
}  
~~~

#### extends的修改

把

~~~
import androidx.appcompat.app.AppCompatActivity;
public class MainActivity extends AppCompatActivity
~~~

改为

~~~
import android.app.Activity;
public class MainActivity extends Activity
~~~



### 类说明

![image-20220407095609413](E:\Document\Typora\img\image-20220407095609413.png)

#### 显示图形的载体GLSurfaceView和Renderer

GLSurfaceView从名字也可以看出，GL开头，继承于SurfaceView，一个专门用于OpenGL的SurfaceView。之所以用SurfaceView，因为他可以用自有的线程去维护页面的刷新，而不依赖于主线程。

创建新类扩展GLSurfaceView才能捕获触摸事件

GLSurfaceView增加了Renderer，用于承担渲染工作，它的使用方法如下：

~~~
	glSurfaceView.setRenderer(new GLSurfaceView.Renderer() {
            @Override
            public void onSurfaceCreated(GL10 gl, EGLConfig config) {

            }

            @Override
            public void onSurfaceChanged(GL10 gl, int width, int height) {

            }

            @Override
            public void onDrawFrame(GL10 gl) {

            }
    });
~~~

+ onSurfaceCreated ：创建GLSurfaceView的时候会走此方法。如果你的GLSurfaceView在按home键调用了onResume、onPause方法，那么从切回此页面的时候依旧会重走一遍此方法。
+ onSurfaceChanged：当视图的几何图形发生变化（例如当设备的屏幕方向发生变化）时调用。
+ onDrawFrame：每次重新绘制视图时调用。
  

### 投影和相机视图

在 ES 2.0 和 3.0 API 中，您可以应用投影或相机视图，只需先分别向图形对象的顶点着色程序添加投影矩阵或相机视图矩阵成员即可。添加此矩阵成员后，您便可以分别生成投影和相机视图矩阵，并将它们应用到您的对象。

1. 为顶点着色程序添加矩阵

   \- 为视图投影矩阵创建一个变量，并将其作为着色程序位置的调节系数添加。以下顶点着色程序代码示例中包含一个`uMVPMatrix`成员，它使您可以将投影和相机视图矩阵应用到使用此着色程序的对象的坐标。

   ```java
   private final String vertexShaderCode =
   
       // This matrix member variable provides a hook to manipulate
       // the coordinates of objects that use this vertex shader.
       "uniform mat4 uMVPMatrix;   \n" +
   
       "attribute vec4 vPosition;  \n" +
       "void main(){               \n" +
       // The matrix must be included as part of gl_Position
       // Note that the uMVPMatrix factor *must be first* in order
       // for the matrix multiplication product to be correct.
       " gl_Position = uMVPMatrix * vPosition; \n" +
   
       "}  \n";
       
   ```

   **注意**：上述示例在顶点着色程序中定义了单个转换矩阵成员，您可以在该着色程序中应用合并后的投影矩阵和相机视图矩阵。根据您的应用的要求，您可能需要在顶点着色程序中定义单独的投影矩阵和相机视图矩阵成员，以便单独更改它们。

2. 访问着色程序矩阵

   \- 在顶点着色程序中创建钩子机制以分别应用投影和相机视图后，您可以访问该变量，以应用投影和相机查看矩阵。以下代码展示了如何通过修改`GLSurfaceView.Renderer`实现的`onSurfaceCreated()`方法来访问上述顶点着色程序中定义的矩阵变量。

   ```java
   public void onSurfaceCreated(GL10 unused, EGLConfig config) {
       ...
           muMVPMatrixHandle = GLES20.glGetUniformLocation(program, "uMVPMatrix");
       ...
   }
       
   ```

3. 创建投影和相机视图矩阵

   \- 生成要应用于图形对象的投影和视图矩阵。以下示例代码展示了如何通过修改`GLSurfaceView.Renderer`实现的`onSurfaceCreated()`和`onSurfaceChanged()`方法，根据设备的屏幕宽高比创建相机视图矩阵和投影矩阵。

   ```java
       public void onSurfaceCreated(GL10 unused, EGLConfig config) {
           ...
           // Create a camera view matrix
           Matrix.setLookAtM(vMatrix, 0, 0, 0, -3, 0f, 0f, 0f, 0f, 1.0f, 0.0f);
       }
   
       public void onSurfaceChanged(GL10 unused, int width, int height) {
           GLES20.glViewport(0, 0, width, height);
   
           float ratio = (float) width / height;
   
           // create a projection matrix from device screen geometry
           Matrix.frustumM(projMatrix, 0, -ratio, ratio, -1, 1, 3, 7);
       }
       
   ```

4. 应用投影和相机视图矩阵

   \- 要应用投影和相机视图转换，请将这些矩阵相乘，然后再将它们设置到顶点着色程序中。以下示例代码展示了如何通过修改

    `GLSurfaceView.Renderer`实现的`onDrawFrame()`方法，合并在上述代码中创建的投影矩阵和相机视图，然后将其应用到将由 OpenGL 渲染的图形对象。

   ```java
       public void onDrawFrame(GL10 unused) {
           ...
           // Combine the projection and camera view matrices
           Matrix.multiplyMM(vPMatrix, 0, projMatrix, 0, vMatrix, 0);
   
           // Apply the combined projection and camera view transformations
           GLES20.glUniformMatrix4fv(muMVPMatrixHandle, 1, false, vPMatrix, 0);
   
           // Draw objects
           ...
       }
       
   ```

#### 相机视图|正交投影|透视投影

当用手机拍照时，我们所在的高度不同，远近不同，拿手机的姿势不一样，都会导致我们拍出来的照片不同，而拍出来的照片，就是**相机视图**。那我们看看如何设置相机视图

~~~
Matrix.setLookAtM (float[] rm,      //接收相机变换矩阵
                int rmOffset,       //变换矩阵的起始位置（偏移量）
                float eyeX,float eyeY, float eyeZ,   //相机位置
                float centerX,float centerY,float centerZ,  //观测物体位置（也就是我们物体所在的位置）
                float upX,float upY,float upZ)  //up向量在xyz上的分量
~~~

投影分为**正交投影**和**透视投影**

+ 正交投影

~~~
Matrix.orthoM (float[] m,           //接收正交投影的变换矩阵
                int mOffset,        //变换矩阵的起始位置（偏移量）
                float left,         //相对观察点近面的左边距
                float right,        //相对观察点近面的右边距
                float bottom,       //相对观察点近面的下边距
                float top,          //相对观察点近面的上边距
                float near,         //相对观察点近面距离
                float far)          //相对观察点远面距离
~~~

+ 透视投影

~~~
Matrix.orthoM (float[] m,           //接收正交投影的变换矩阵
                int mOffset,        //变换矩阵的起始位置（偏移量）
                float left,         //相对观察点近面的左边距
                float right,        //相对观察点近面的右边距
                float bottom,       //相对观察点近面的下边距
                float top,          //相对观察点近面的上边距
                float near,         //相对观察点近面距离
                float far)          //相对观察点远面距离
~~~

#### 绘制方法

`onDraw()`中绘制方法：

1. 顶点法 `GLES20.glDrawArrays` ，根据我们传入的点去一个一个的绘制
2. 索引法`GLES20.glDrawElements`，根据我们传入的索引序列，去顶点序列中寻找对应的顶点，然后去绘制图形。索引法的优势就是相比顶点法减少很多重复顶点占用空间。

GLES20.glDrawArrays的第一个参数表示绘制方式，第二个参数表示偏移量，第三个参数表示顶点个数。接下来我们来看看都有哪些绘制方式

int GL_POINTS //将传入的顶点坐标作为单独的点绘制
int GL_LINES //将传入的坐标作为单独线条绘制，ABCDEFG六个顶点，绘制AB、CD、EF三条线
int GL_LINE_STRIP //将传入的顶点作为折线绘制，ABCD四个顶点，绘制AB、BC、CD三条线
int GL_LINE_LOOP //将传入的顶点作为闭合折线绘制，ABCD四个顶点，绘制AB、BC、CD、DA四条线。
int GL_TRIANGLES //将传入的顶点作为单独的三角形绘制，ABCDEF绘制ABC,DEF两个三角形
int GL_TRIANGLE_FAN //将传入的顶点作为扇面绘制，ABCDEF绘制ABC、ACD、ADE、AEF四个三角形
int GL_TRIANGLE_STRIP //将传入的顶点作为三角条带绘制，ABCDEF绘制ABC,BCD,CDE,DEF四个三角形

代码调用逻辑：

~~~
@Override
public void onDraw(float[] mMVPMatrix) {
    //将程序加入到OpenGLES2.0环境
    GLES20.glUseProgram(mProgram);
    //获取变换矩阵vMatrix成员句柄
    mMatrixHandler = GLES20.glGetUniformLocation(mProgram, "vMatrix");
    //指定vMatrix的值
    GLES20.glUniformMatrix4fv(mMatrixHandler, 1, false, mMVPMatrix, 0);
    //获取顶点着色器的vPosition成员句柄
    mPositionHandle = GLES20.glGetAttribLocation(mProgram, "vPosition");
    //启用三角形顶点的句柄
    GLES20.glEnableVertexAttribArray(mPositionHandle);
    //准备三角形的坐标数据
    GLES20.glVertexAttribPointer(mPositionHandle, COORDS_PER_VERTEX,
    GLES20.GL_FLOAT, false,
    vertexStride, vertexBuffer);
    //获取片元着色器的vColor成员的句柄
    mColorHandle = GLES20.glGetUniformLocation(mProgram, "vColor");
    //设置绘制三角形的颜色
    GLES20.glUniform4fv(mColorHandle, 1, color, 0);
    //绘制三角形
    GLES20.glDrawArrays(GLES20.GL_TRIANGLE_FAN, 0, shapePos.length / 3);
    //禁止顶点数组的句柄
    GLES20.glDisableVertexAttribArray(mPositionHandle);
}
~~~

开启深度缓冲GLES20.glEnable(GLES20.GL_DEPTH_TEST)，同时在绘制前也要对应的去清除深度缓冲GLES20.glClear(GLES20.GL_DEPTH_BUFFER_BIT)。那么何为深度缓冲

在计算机图形学中，深度缓冲是在三维图形中处理图像深度坐标的过程，这个过程通常在硬件中完成，它也可以在软件中完成，它是可见性问题的一个解决方法。可见性问题是确定渲染场景中哪部分可见、哪部分不可见的问题。画家算法是另外一种常用的方法，尽管效率较低，但是也可以处理透明场景元素。深度缓冲也称为Z缓冲。



#### 变换

+ 平移变换

~~~
Matrix.translateM(currMatrix, 0, x, y, z);
~~~

+ 旋转变换

~~~
Matrix.rotateM(currMatrix, 0, angle, x, y, z);
~~~

+ 缩放变换

~~~
Matrix.rotateM(currMatrix, 0, angle, x, y, z);
~~~

### obj文件格式

[Android OpenGL ES2.0从放弃到入门（五）——绘制3D模型（obj+mtl）_有梦想的咸鱼9527的博客-CSDN博客](https://blog.csdn.net/weixin_39560693/article/details/95622136)

它是一种可以保存3D模型信息的文件，我们可以举个例子看看他内部都可以保存哪些信息。

~~~
# mtl材质文件
 mtllib testvt.mtl

# o 对象名称(Object name)
o adfaf

# 组名称
g default

# 顶点
v 0 0.5 0
v -0.5 -0.5 0
v 0.5 -0.5 0

# 纹理坐标
vt 0.0 1.0
vt 0.0 0.0
vt 1.0 1.0

# 顶点法线
vn 0 0 1
# 当前图元所用材质
usemtl Default
s off
f 1/1/1 2/2/1 3/3/1
~~~

详细内容

~~~
顶点数据(Vertex data)：

v 几何体顶点(Geometric vertices)
vt 贴图坐标点(Texture vertices)
vn 顶点法线(Vertex normals)
vp 参数空格顶点 (Parameter space vertices)
自由形态曲线(Free-form curve)/表面属性(surface attributes):

deg 度(Degree)
bmat 基础矩阵(Basis matrix)
step 步尺寸(Step size)
cstype 曲线或表面类型 (Curve or surface type)
元素(Elements):

p 点(Point)
l 线(Line)
f 面(Face)
curv 曲线(Curve)
curv2 2D曲线(2D curve)
surf 表面(Surface)
自由形态曲线(Free-form curve)/表面主体陈述(surface body statements):

parm 参数值(Parameter values )
trim 外部修剪循环(Outer trimming loop)
hole 内部整修循环(Inner trimming loop)
scrv 特殊曲线(Special curve)
sp 特殊的点(Special point)
end 结束陈述(End statement)
自由形态表面之间的连接(Connectivity between free-form surfaces):

con 连接 (Connect)
成组(Grouping):

g 组名称(Group name)
s 光滑组(Smoothing group)
mg 合并组(Merging group)
o 对象名称(Object name)
显示(Display)/渲染属性(render attributes):

bevel 导角插值(Bevel interpolation)
c_interp 颜色插值(Color interpolation)
d_interp 溶解插值(Dissolve interpolation)
lod 细节层次(Level of detail)
usemtl 材质名称(Material name)
mtllib 材质库(Material library)
shadow_obj 投射阴影(Shadow casting)
trace_obj 光线跟踪(Ray tracing)
ctech 曲线近似技术(Curve approximation technique)
stech 表面近似技术 (Surface approximation technique)
~~~

以上为obj文件的大致格式。

+ 开头的为注释

v 表示本行指定一个顶点。 前缀后跟着3个单精度浮点数，分别表示该定点的X、Y、Z坐标值

vt 表示本行指定一个纹理坐标。此前缀后跟着两个单精度浮点数。分别表示此纹理坐标的U、V值

vn 表示本行指定一个法线向量。此前缀后跟着3个单精度浮点数，分别表示该法向量的X、Y、Z坐标值

f 表示本行指定一个表面(Face)。一个表面实际上就是一个三角形图元

s表示一个组

usemtl 此前缀后只跟着一个参数。该参数指定了从此行之后到下一个以usemtl开头的行之间的所有表面所使用的材质名称。该材质可以在此OBJ文件所附属的MTL文件中找到具体信息。

mtllib 此前缀后只跟着一个参数。该参数指定了此OBJ文件所使用的材质库文件(*.mtl)的文件路径
当然obj的文件格式可不止这些，这里列出来我们常见的一些格式，想了解详细的童鞋，可移步大神的文章3D中的

+ OBJ文件格式详解

有一点值得注意的是，之前我们介绍过，OpenGL ES相比OpenGL舍弃了很多图形绘制，任何的事物都是由三角形绘制而成。obj文件是通过专业的3D模型绘制软件形成的，在电脑上制作的文件，可不一定都是依照三角形去绘制的，而且每个模型数据也存在差异。所以我们的f标签可能存在不同的格式，这里列举下

+ f 1 2 3 这样的行表示以第1、2、3号顶点组成一个三角形。
+ f 1/3 2/5 3/4 这样的行表示以第1、2、3号顶点组成一个三角形，其中第一个顶点的纹理坐标的索引值为3，第二个顶点的纹理坐标的索引值为5，第三个顶点的纹理坐标的索引值为4。
+ f 1/3/4 2/5/6 3/4/2 这样的行表示以第1、2、3号顶点组成一个三角形，其中第一个顶点的纹理坐标的索引值为3，其法线的索引值是4；第二个顶点的纹理坐标的索引值为5，其法线的索引值是6；第三个顶点的纹理坐标的索引值为6，其法线的索引值是2。
+ f 1//4 2//6 3//2这样的行表示以第1、2、3号顶点组成一个三角形，且忽略纹理坐标。其中第一个顶点的法线的索引值是4；第二个顶点的法线的索引值是6；第三个顶点的法线的索引值是2。
+ f 1 2 3 4 同第一种情况，只不过，此处为四边形，而不是三角形。
  上述的索引坐标都是从1开始，这里与我们写代码从0开始有些不同

### mtl文件格式

保存我们物体的颜色。我们物体的颜色保存在mtl文件中。

~~~
# 定义一个名为 'Default'的材质
newmtl Default
#exponent指定材质的反射指数，定义了反射高光度
Ns 96.078431
# 材质的环境光
Ka 0 0 0
# 散射光
Kd 0.784314 0.784314 0.784314
# 镜面光
Ks 0 0 0

# 透明度
d 1

# 为漫反射指定颜色纹理文件
map_Kd test_vt.png
map_Ka picture1.png #阴影纹理贴图
map_Ks picture2.png #高光纹理贴图
illum 2 #光照模型

#光照模型属性如下：
 #0. 色彩开，阴影色关
 #1. 色彩开，阴影色开
 #2. 高光开
 #3. 反射开，光线追踪开
 #4. 透明： 玻璃开 反射：光线追踪开
 #5. 反射：菲涅尔衍射开，光线追踪开
 #6. 透明：折射开 反射：菲涅尔衍射关，光线追踪开
 #7. 透明：折射开 反射：菲涅尔衍射开，光线追踪开
 #8. 反射开，光线追踪关
 #9. 透明： 玻璃开 反射：光线追踪关
 #10. 投射阴影于不可见表面
~~~



## 触摸机制

TouchListener是基于[监听](https://so.csdn.net/so/search?q=监听&spm=1001.2101.3001.7020)的，OnTouchEvent则是基于回调的。

![image-20220414152000843](E:\Document\Typora\img\image-20220414152000843.png)





# JAVA

## 字符串读取解析

~~~
String line = null;
// 读取assets下文件
InputStream in = res.getAssets().open(fname);
InputStreamReader isr = new InputStreamReader(in);
BufferedReader buffer = new BufferedReader(isr);

// 循环读取每一行的数据
while ((line = buffer.readLine()) != null) {
    // 忽略 空行和注释
    if (line.length() == 0 || line.charAt(0) == '#') {
    continue;
    }
    // 以空格分割String
    StringTokenizer parts = new StringTokenizer(line, " ");
    int numTokens = parts.countTokens();
~~~

StringTokenizer (String str) ：构造一个用来解析 str 的 StringTokenizer 对象。. java 默认的分隔符是空格 ("")、制表符 (\t)、换行符 (\n)、回车符 (\r)。

+ StringTokenizer的方法

**hasMoreTokens()方法**用于检查从此标准时间开始是否还有字符串。

